{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48e17b6",
   "metadata": {},
   "source": [
    "Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & Configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    # File paths\n",
    "    RAW_DATA_PATH = \"data/raw_conversation.xlsx\"\n",
    "    PROCESSED_DATA_PATH = \"data/processed/conversations.pkl\"\n",
    "    MODEL_SAVE_PATH = \"models/\"\n",
    "    \n",
    "    # ML Configuration\n",
    "    TEST_SIZE = 0.2\n",
    "    RANDOM_STATE = 42\n",
    "    \n",
    "    # Time thresholds (dalam menit)\n",
    "    NORMAL_THRESHOLD = 5\n",
    "    SERIOUS_FIRST_REPLY_THRESHOLD = 5\n",
    "    SERIOUS_FINAL_REPLY_THRESHOLD = 480  # 8 jam\n",
    "    COMPLAINT_FINAL_REPLY_THRESHOLD = 7200  # 5 hari\n",
    "    \n",
    "    # Abandoned detection\n",
    "    ABANDONED_TIMEOUT_MINUTES = 60  # 1 jam tanpa response\n",
    "    NO_CONVERSATION_TIMEOUT_MINUTES = 30  # 30 menit tanpa meaningful interaction\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Create directories\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "Path(\"output\").mkdir(exist_ok=True)\n",
    "Path(\"output/reports\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"output/visualizations\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cf9a8",
   "metadata": {},
   "source": [
    "Data Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f079890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessor\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.role_mapping = {\n",
    "            'bot': 'Bot',\n",
    "            'customer': 'Customer', \n",
    "            'operator': 'Operator',\n",
    "            'ticket automation': 'Ticket Automation'\n",
    "        }\n",
    "    \n",
    "    def load_raw_data(self, file_path):\n",
    "        \"\"\"Load data dari Excel dengan format yang ditentukan\"\"\"\n",
    "        print(f\"üìñ Loading data from {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "            print(f\"‚úÖ Loaded {len(df)} rows\")\n",
    "            \n",
    "            # Validasi columns\n",
    "            required_columns = ['No', 'Ticket Number', 'Role', 'Sender', 'Message Date', 'Message']\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                print(f\"‚ö†Ô∏è Missing columns: {missing_columns}\")\n",
    "                return None\n",
    "            \n",
    "            # Clean data\n",
    "            df = self.clean_data(df)\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def clean_data(self, df):\n",
    "        \"\"\"Clean dan preprocess data\"\"\"\n",
    "        # Copy dataframe\n",
    "        df_clean = df.copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        df_clean = df_clean.dropna(subset=['Message', 'Ticket Number'])\n",
    "        \n",
    "        # Clean text\n",
    "        df_clean['Message'] = df_clean['Message'].astype(str).str.strip()\n",
    "        \n",
    "        # Parse timestamp\n",
    "        df_clean['parsed_timestamp'] = pd.to_datetime(\n",
    "            df_clean['Message Date'], errors='coerce'\n",
    "        )\n",
    "        \n",
    "        # Remove invalid timestamps\n",
    "        initial_count = len(df_clean)\n",
    "        df_clean = df_clean[df_clean['parsed_timestamp'].notna()]\n",
    "        final_count = len(df_clean)\n",
    "        print(f\"üìÖ Valid timestamps: {final_count}/{initial_count}\")\n",
    "        \n",
    "        # Standardize roles\n",
    "        df_clean['Role'] = df_clean['Role'].str.lower().map(\n",
    "            lambda x: self.role_mapping.get(x, x.title())\n",
    "        )\n",
    "        \n",
    "        # Filter meaningful messages\n",
    "        df_clean = df_clean[df_clean['Message'].str.len() > 1]\n",
    "        \n",
    "        print(f\"üßπ Cleaned data: {len(df_clean)} rows\")\n",
    "        return df_clean\n",
    "    \n",
    "    def detect_conversation_start(self, ticket_df):\n",
    "        \"\"\"Deteksi kapan conversation benar-benar dimulai dengan operator\"\"\"\n",
    "        operator_greeting_patterns = [\n",
    "            r\"halo bapak/ibu.*selamat datang di livechat.*saya.*akan membantu\",\n",
    "            r\"Selamat datang di livechat\",\n",
    "            r\"Selamat.*, .* Selamat datang di layanan Live Chat Toyota Astra Motor. Dengan .*, apakah ada yang bisa dibantu?\",\n",
    "            r\"hai.*selamat datang\",\n",
    "            r\"halo.*selamat datang\"\n",
    "        ]\n",
    "        \n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            message = str(row['Message']).lower()\n",
    "            role = str(row['Role']).lower()\n",
    "            \n",
    "            # Cari pattern greeting operator\n",
    "            if 'operator' in role:\n",
    "                for pattern in operator_greeting_patterns:\n",
    "                    if re.search(pattern, message):\n",
    "                        return row['parsed_timestamp']\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Test preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "raw_df = preprocessor.load_raw_data(config.RAW_DATA_PATH)\n",
    "\n",
    "if raw_df is not None:\n",
    "    print(f\"üìä Data preview:\")\n",
    "    print(f\"   Columns: {list(raw_df.columns)}\")\n",
    "    print(f\"   Shape: {raw_df.shape}\")\n",
    "    print(f\"   Ticket count: {raw_df['Ticket Number'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bdb52b",
   "metadata": {},
   "source": [
    "Conversation Parser & Q-A Pair Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c156f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONVERSATION PARSER - FIXED VERSION =====\n",
    "class ConversationParser:\n",
    "    def __init__(self):\n",
    "        self.question_indicators = [\n",
    "            '?', 'apa', 'bagaimana', 'berapa', 'kapan', 'dimana', 'kenapa',\n",
    "            'bisa', 'boleh', 'minta', 'tolong', 'tanya', 'info', 'caranya',\n",
    "            'mau tanya', 'boleh tanya', 'minta info', 'berapa harga',\n",
    "            'bagaimana cara', 'bisa tolong', 'mohon bantuan', 'gimana',\n",
    "            'promo', 'error', 'rusak', 'masalah', 'mogok', 'gagal', 'tidak bisa',\n",
    "            'harga', 'biaya', 'tarif', 'fungsi', 'cara', 'solusi', 'bantuan'\n",
    "        ]\n",
    "        \n",
    "        self.operator_greeting_patterns = [\n",
    "            r\"selamat\\s+(pagi|siang|sore|malam)\",\n",
    "            r\"selamat\\s+\\w+\\s+selamat\\s+datang\",\n",
    "            r\"selamat\\s+datang\",\n",
    "            r\"dengan\\s+\\w+\\s+apakah\\s+ada\",\n",
    "            r\"ada\\s+yang\\s+bisa\\s+dibantu\",\n",
    "            r\"boleh\\s+dibantu\",\n",
    "            r\"bisa\\s+dibantu\", \n",
    "            r\"halo.*selamat\",\n",
    "            r\"hai.*selamat\",\n",
    "            r\"perkenalkan.*saya\",\n",
    "            r\"layanan\\s+live\\s+chat\",\n",
    "            r\"live\\s+chat\\s+toyota\",\n",
    "            r\"toyota\\s+astra\\s+motor\"\n",
    "        ]\n",
    "        \n",
    "        self.bot_patterns = [\n",
    "            'klik.*setuju', 'data privasi', 'virtual assistant', 'silakan memilih',\n",
    "            'pilih menu', 'silahkan ketik nama', 'halo kak', 'bucket', 'media-images',\n",
    "            'pusat bantuan', 'main menu', 'feedback'\n",
    "        ]\n",
    "        \n",
    "        self.generic_reply_patterns = [\n",
    "            'terima kasih telah menghubungi',\n",
    "            'silakan pilih menu',\n",
    "            'virtual assistant',\n",
    "            'akan segera menghubungi',\n",
    "            'dalam antrian',\n",
    "            'tunggu sebentar',\n",
    "            'terima kasih, saat ini anda masuk',\n",
    "            'customer service akan',\n",
    "            'menghubungi anda'\n",
    "        ]\n",
    "    \n",
    "    def detect_conversation_start(self, ticket_df):\n",
    "        \"\"\"Deteksi kapan conversation benar-benar dimulai dengan operator\"\"\"\n",
    "        ticket_df = ticket_df.sort_values('parsed_timestamp').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   üîç Analyzing {len(ticket_df)} messages for conversation start...\")\n",
    "        \n",
    "        # METHOD 1: Cari operator greeting message\n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            message = str(row['Message']).lower()\n",
    "            role = str(row['Role']).lower()\n",
    "            \n",
    "            if self._is_bot_message(message, role):\n",
    "                continue\n",
    "                \n",
    "            if any(keyword in role for keyword in ['operator', 'agent', 'admin', 'cs']):\n",
    "                for pattern in self.operator_greeting_patterns:\n",
    "                    if re.search(pattern, message, re.IGNORECASE):\n",
    "                        print(f\"   ‚úÖ Conversation start: operator greeting at position {idx}\")\n",
    "                        return row['parsed_timestamp']\n",
    "        \n",
    "        # METHOD 2: Cari first operator response to meaningful customer question\n",
    "        meaningful_questions = []\n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            role = str(row['Role']).lower()\n",
    "            message = str(row['Message']).lower()\n",
    "            \n",
    "            if self._is_bot_message(message, role):\n",
    "                continue\n",
    "                \n",
    "            if any(keyword in role for keyword in ['customer', 'user', 'pelanggan']):\n",
    "                if self._is_meaningful_message(message):\n",
    "                    meaningful_questions.append({\n",
    "                        'index': idx, 'time': row['parsed_timestamp'], 'message': message\n",
    "                    })\n",
    "            \n",
    "            elif meaningful_questions and any(keyword in role for keyword in ['operator', 'agent']):\n",
    "                last_question = meaningful_questions[-1]\n",
    "                time_gap = (row['parsed_timestamp'] - last_question['time']).total_seconds()\n",
    "                \n",
    "                if time_gap < 1800:  # 30 menit\n",
    "                    print(f\"   ‚úÖ Conversation start: first operator response at position {idx}\")\n",
    "                    return last_question['time']\n",
    "        \n",
    "        # Fallback methods\n",
    "        if meaningful_questions:\n",
    "            print(f\"   ‚ö†Ô∏è  Conversation start: first meaningful question\")\n",
    "            return meaningful_questions[0]['time']\n",
    "            \n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            message = str(row['Message']).lower()\n",
    "            role = str(row['Role']).lower()\n",
    "            \n",
    "            if not self._is_bot_message(message, role):\n",
    "                print(f\"   ‚ö†Ô∏è  Conversation start: first non-bot message\")\n",
    "                return row['parsed_timestamp']\n",
    "        \n",
    "        if len(ticket_df) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Conversation start: first message\")\n",
    "            return ticket_df.iloc[0]['parsed_timestamp']\n",
    "        \n",
    "        print(\"   ‚ùå No conversation start detected\")\n",
    "        return None\n",
    "    \n",
    "    def parse_conversation(self, ticket_df):\n",
    "        \"\"\"Parse conversation menjadi Q-A pairs - FIXED SORTING VERSION\"\"\"\n",
    "        conversation_start = self.detect_conversation_start(ticket_df)\n",
    "        \n",
    "        if not conversation_start:\n",
    "            print(\"   ‚ö†Ô∏è  Using all non-bot messages\")\n",
    "            conv_df = self._filter_bot_messages(ticket_df)\n",
    "        else:\n",
    "            conv_df = self._filter_bot_messages(ticket_df)\n",
    "            conv_df = conv_df[conv_df['parsed_timestamp'] >= conversation_start]\n",
    "        \n",
    "        print(f\"   üìù Analyzing {len(conv_df)} meaningful messages\")\n",
    "        \n",
    "        if len(conv_df) == 0:\n",
    "            print(\"   ‚ùå No meaningful messages after filtering\")\n",
    "            return []\n",
    "        \n",
    "        # üî• FIX: URUTKAN DATA BERDASARKAN TIMESTAMP DULU!\n",
    "        conv_df = conv_df.sort_values('parsed_timestamp').reset_index(drop=True)\n",
    "        print(f\"   üîÑ Sorted messages by timestamp\")\n",
    "        \n",
    "        qa_pairs = []\n",
    "        current_question = None\n",
    "        question_time = None\n",
    "        question_context = []\n",
    "        last_customer_time = None\n",
    "        \n",
    "        # Track position untuk debugging\n",
    "        message_positions = []\n",
    "        \n",
    "        for idx, row in conv_df.iterrows():\n",
    "            role = str(row['Role']).lower()\n",
    "            message = str(row['Message'])\n",
    "            timestamp = row['parsed_timestamp']\n",
    "            \n",
    "            message_positions.append({\n",
    "                'position': idx,\n",
    "                'time': timestamp,\n",
    "                'role': role,\n",
    "                'message': message[:50] + '...' if len(message) > 50 else message\n",
    "            })\n",
    "            \n",
    "            # CUSTOMER MESSAGE\n",
    "            if any(keyword in role for keyword in ['customer', 'user', 'pelanggan']):\n",
    "                last_customer_time = timestamp\n",
    "                \n",
    "                if self._is_meaningful_message(message):\n",
    "                    # Jika ada previous question yang belum dijawab, simpan dulu\n",
    "                    if current_question and question_context:\n",
    "                        self._save_qa_pair(qa_pairs, question_context, question_time, None, None, position=idx)\n",
    "                    \n",
    "                    # Start new question\n",
    "                    current_question = message\n",
    "                    question_time = timestamp\n",
    "                    question_context = [message]\n",
    "                \n",
    "                elif current_question and question_context:\n",
    "                    # Check jika ini bagian dari bubble chat yang sama\n",
    "                    time_gap = (timestamp - question_time).total_seconds()\n",
    "                    if time_gap < 300:  # 5 menit\n",
    "                        question_context.append(message)\n",
    "                        question_time = timestamp  # Update ke timestamp terakhir\n",
    "                    else:\n",
    "                        # Bubble chat baru\n",
    "                        self._save_qa_pair(qa_pairs, question_context, question_time, None, None, position=idx)\n",
    "                        current_question = message\n",
    "                        question_time = timestamp\n",
    "                        question_context = [message]\n",
    "            \n",
    "            # OPERATOR MESSAGE - potential answer\n",
    "            elif current_question and question_context and any(keyword in role for keyword in ['operator', 'agent', 'admin', 'cs']):\n",
    "                # Skip jika ini generic reply\n",
    "                if self._is_generic_reply(message):\n",
    "                    continue\n",
    "                \n",
    "                # Pastikan ini benar-benar jawaban (bukan greeting awal)\n",
    "                time_gap = (timestamp - question_time).total_seconds()\n",
    "                \n",
    "                # üî• FIX: JANGAN PAKAI MINIMAL 1 MENIT, PAKAI LOGIKA LEBIH BAIK\n",
    "                # Cek jika ini operator message pertama setelah customer question\n",
    "                if time_gap >= 0:  # Boleh 0 atau positif (setelah question)\n",
    "                    lead_time = time_gap\n",
    "                    self._save_qa_pair(qa_pairs, question_context, question_time, message, timestamp, role, lead_time, position=idx)\n",
    "                    \n",
    "                    # Reset untuk next question\n",
    "                    current_question = None\n",
    "                    question_time = None\n",
    "                    question_context = []\n",
    "        \n",
    "        # Handle last question jika ada\n",
    "        if current_question and question_context:\n",
    "            self._save_qa_pair(qa_pairs, question_context, question_time, None, None, position=len(conv_df))\n",
    "        \n",
    "        # POST-PROCESSING: Cari jawaban untuk unanswered questions\n",
    "        qa_pairs = self._find_missing_answers(conv_df, qa_pairs)\n",
    "        \n",
    "        # üî• FIX: URUTKAN Q-A PAIRS BERDASARKAN QUESTION TIME!\n",
    "        qa_pairs = sorted(qa_pairs, key=lambda x: x['question_time'] if x['question_time'] else pd.Timestamp.min)\n",
    "        \n",
    "        # üî• FIX: TAMBAHKAN POSITION INDEX YANG BENAR BERDASARKAN URUTAN WAKTU\n",
    "        for i, pair in enumerate(qa_pairs):\n",
    "            pair['position'] = i  # Position berdasarkan urutan waktu\n",
    "        \n",
    "        print(f\"   ‚úÖ Found {len(qa_pairs)} Q-A pairs ({sum(1 for p in qa_pairs if p['is_answered'])} answered)\")\n",
    "        \n",
    "        # Debug: Print message sequence\n",
    "        print(f\"   üîç Message sequence (first 5):\")\n",
    "        for msg in message_positions[:5]:\n",
    "            print(f\"      {msg['position']}: {msg['time']} | {msg['role']:15} | {msg['message']}\")\n",
    "        \n",
    "        return qa_pairs\n",
    "    \n",
    "    def _save_qa_pair(self, qa_pairs, question_context, question_time, answer, answer_time, answer_role=None, lead_time=None, position=None):\n",
    "        \"\"\"Save Q-A pair ke list - FIXED dengan position\"\"\"\n",
    "        full_question = \" | \".join(question_context)\n",
    "        \n",
    "        pair_data = {\n",
    "            'question': full_question,\n",
    "            'question_time': question_time,\n",
    "            'bubble_count': len(question_context),\n",
    "            'is_answered': answer is not None,\n",
    "            'position': position if position is not None else len(qa_pairs)  # Default position\n",
    "        }\n",
    "        \n",
    "        if answer:\n",
    "            pair_data.update({\n",
    "                'answer': answer,\n",
    "                'answer_time': answer_time,\n",
    "                'answer_role': answer_role,\n",
    "                'lead_time_seconds': lead_time,\n",
    "                'lead_time_minutes': round(lead_time / 60, 2) if lead_time else None,\n",
    "                'lead_time_hhmmss': self._seconds_to_hhmmss(lead_time) if lead_time else None\n",
    "            })\n",
    "        else:\n",
    "            pair_data.update({\n",
    "                'answer': 'NO_ANSWER',\n",
    "                'answer_time': None,\n",
    "                'answer_role': None,\n",
    "                'lead_time_seconds': None,\n",
    "                'lead_time_minutes': None,\n",
    "                'lead_time_hhmmss': None\n",
    "            })\n",
    "        \n",
    "        qa_pairs.append(pair_data)\n",
    "    \n",
    "    def _find_missing_answers(self, conv_df, qa_pairs):\n",
    "        \"\"\"Cari jawaban untuk questions yang belum terjawab - FIXED SORTING\"\"\"\n",
    "        answered_pairs = [p for p in qa_pairs if p['is_answered']]\n",
    "        unanswered_pairs = [p for p in qa_pairs if not p['is_answered']]\n",
    "        \n",
    "        if not unanswered_pairs:\n",
    "            return qa_pairs\n",
    "        \n",
    "        # Untuk setiap unanswered question, cari operator message setelahnya\n",
    "        for i, pair in enumerate(unanswered_pairs):\n",
    "            question_time = pair['question_time']\n",
    "            \n",
    "            # Cari operator messages setelah question time\n",
    "            subsequent_messages = conv_df[\n",
    "                (conv_df['parsed_timestamp'] > question_time) &\n",
    "                (conv_df['Role'].str.lower().str.contains('operator|agent|admin|cs', na=False))\n",
    "            ].sort_values('parsed_timestamp')  # üî• FIX: URUTKAN\n",
    "            \n",
    "            if not subsequent_messages.empty:\n",
    "                # Ambil operator message pertama setelah question\n",
    "                first_operator_msg = subsequent_messages.iloc[0]\n",
    "                \n",
    "                # Skip jika generic reply\n",
    "                if not self._is_generic_reply(first_operator_msg['Message']):\n",
    "                    lead_time = (first_operator_msg['parsed_timestamp'] - question_time).total_seconds()\n",
    "                    \n",
    "                    # Update pair dengan answer yang ditemukan\n",
    "                    pair.update({\n",
    "                        'answer': first_operator_msg['Message'],\n",
    "                        'answer_time': first_operator_msg['parsed_timestamp'],\n",
    "                        'answer_role': first_operator_msg['Role'],\n",
    "                        'lead_time_seconds': lead_time,\n",
    "                        'lead_time_minutes': round(lead_time / 60, 2),\n",
    "                        'lead_time_hhmmss': self._seconds_to_hhmmss(lead_time),\n",
    "                        'is_answered': True\n",
    "                    })\n",
    "                    print(f\"   üîç Found missing answer for question {i+1}\")\n",
    "        \n",
    "        return answered_pairs + unanswered_pairs\n",
    "    \n",
    "    def _filter_bot_messages(self, df):\n",
    "        \"\"\"Filter out bot messages dari dataframe\"\"\"\n",
    "        return df[~df.apply(\n",
    "            lambda row: self._is_bot_message(str(row['Message']).lower(), str(row['Role']).lower()), \n",
    "            axis=1\n",
    "        )].copy()\n",
    "    \n",
    "    def _is_bot_message(self, message, role):\n",
    "        \"\"\"Check jika message dari bot\"\"\"\n",
    "        if any(keyword in role for keyword in ['bot', 'system', 'virtual', 'automation']):\n",
    "            return True\n",
    "        return any(pattern in message for pattern in self.bot_patterns)\n",
    "    \n",
    "    def _is_meaningful_message(self, message):\n",
    "        \"\"\"Check jika message meaningful untuk analysis\"\"\"\n",
    "        if not message or len(message.strip()) < 3:\n",
    "            return False\n",
    "            \n",
    "        message_lower = message.lower().strip()\n",
    "        \n",
    "        # Skip very short messages yang cuma greetings/consent\n",
    "        greetings = ['halo', 'hai', 'hi', 'selamat', 'pagi', 'siang', 'sore', 'malam']\n",
    "        consent_words = ['setuju', 'consent', 'agree', 'ok', 'oke', 'iya', 'yes']\n",
    "        menu_words = ['menu', 'pusatbantuan', 'mainmenu', 'kembali', 'others']\n",
    "        \n",
    "        words = message_lower.split()\n",
    "        if len(words) <= 2:\n",
    "            if any(word in words for word in greetings + consent_words + menu_words):\n",
    "                return False\n",
    "        \n",
    "        # Skip pure consent messages\n",
    "        if any(word in message_lower for word in consent_words) and len(message_lower) < 10:\n",
    "            return False\n",
    "            \n",
    "        # Skip menu navigation\n",
    "        if any(word in message_lower for word in menu_words) and len(message_lower) < 15:\n",
    "            return False\n",
    "        \n",
    "        # Question indicators\n",
    "        has_question_indicator = any(indicator in message_lower for indicator in self.question_indicators)\n",
    "        has_question_mark = '?' in message_lower\n",
    "        \n",
    "        # Meaningful content check\n",
    "        meaningful_words = [w for w in words if len(w) > 2 and w not in greetings + consent_words + menu_words]\n",
    "        has_meaningful_content = len(meaningful_words) >= 2\n",
    "        \n",
    "        return (has_question_indicator and has_meaningful_content) or has_question_mark or len(meaningful_words) >= 3\n",
    "    \n",
    "    def _is_generic_reply(self, message):\n",
    "        \"\"\"Skip generic/bot replies\"\"\"\n",
    "        message_lower = str(message).lower()\n",
    "        return any(pattern in message_lower for pattern in self.generic_reply_patterns)\n",
    "    \n",
    "    def _seconds_to_hhmmss(self, seconds):\n",
    "        \"\"\"Convert seconds to HH:MM:SS format\"\"\"\n",
    "        try:\n",
    "            hours = int(seconds // 3600)\n",
    "            minutes = int((seconds % 3600) // 60)\n",
    "            seconds = int(seconds % 60)\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        except:\n",
    "            return \"00:00:00\"\n",
    "\n",
    "    def _calculate_real_lead_time(self, ticket_data, customer_messages, agent_messages):\n",
    "        \"\"\"Calculate REAL lead time dari timestamps - FIXED VERSION\"\"\"\n",
    "        try:\n",
    "            if 'Message Date' not in ticket_data.columns:\n",
    "                # Estimate based on message count jika tidak ada timestamp\n",
    "                if customer_messages and agent_messages:\n",
    "                    return len(agent_messages) * 5.0  # Estimate 5 minutes per reply\n",
    "                return 10.0  # Default\n",
    "            \n",
    "            # Convert to datetime dengan error handling\n",
    "            ticket_data = ticket_data.copy()\n",
    "            \n",
    "            # Debug: Check original Message Date values\n",
    "            print(f\"DEBUG: Original Message Date sample: {ticket_data['Message Date'].head(3).tolist()}\")\n",
    "            \n",
    "            # Try different date parsing strategies\n",
    "            ticket_data['parsed_timestamp'] = pd.to_datetime(\n",
    "                ticket_data['Message Date'], \n",
    "                errors='coerce',\n",
    "                format='mixed'  # Try multiple formats\n",
    "            )\n",
    "            \n",
    "            # Check for parsing failures\n",
    "            failed_parses = ticket_data['parsed_timestamp'].isna().sum()\n",
    "            if failed_parses > 0:\n",
    "                print(f\"‚ö†Ô∏è Failed to parse {failed_parses} timestamps\")\n",
    "                \n",
    "                # Try alternative parsing\n",
    "                ticket_data['parsed_timestamp'] = pd.to_datetime(\n",
    "                    ticket_data['Message Date'], \n",
    "                    errors='coerce',\n",
    "                    dayfirst=True  # Try day-first format\n",
    "                )\n",
    "            \n",
    "            # Drop rows with invalid dates\n",
    "            valid_data = ticket_data.dropna(subset=['parsed_timestamp'])\n",
    "            \n",
    "            if len(valid_data) < 2:\n",
    "                print(\"‚ö†Ô∏è Not enough valid timestamps, using fallback\")\n",
    "                return 10.0  # Default jika tidak cukup data\n",
    "            \n",
    "            # üî• FIX: URUTKAN DATA BERDASARKAN TIMESTAMP!\n",
    "            valid_data = valid_data.sort_values('parsed_timestamp')\n",
    "            \n",
    "            print(f\"DEBUG: First message: {valid_data.iloc[0]['parsed_timestamp']}\")\n",
    "            print(f\"DEBUG: Last message: {valid_data.iloc[-1]['parsed_timestamp']}\")\n",
    "            \n",
    "            # Find first customer message time\n",
    "            customer_messages_times = []\n",
    "            agent_messages_times = []\n",
    "            \n",
    "            for idx, row in valid_data.iterrows():\n",
    "                role_str = str(row['Role']).lower()\n",
    "                message_time = row['parsed_timestamp']\n",
    "                \n",
    "                if any(keyword in role_str for keyword in ['customer', 'user', 'pelanggan']):\n",
    "                    customer_messages_times.append(message_time)\n",
    "                elif any(keyword in role_str for keyword in ['operator', 'agent', 'admin', 'cs']):\n",
    "                    agent_messages_times.append(message_time)\n",
    "            \n",
    "            if not customer_messages_times:\n",
    "                print(\"‚ö†Ô∏è No customer messages found\")\n",
    "                return 15.0\n",
    "            \n",
    "            if not agent_messages_times:\n",
    "                print(\"‚ö†Ô∏è No agent messages found\")\n",
    "                return 15.0\n",
    "            \n",
    "            # Ambil timestamp pertama customer dan agent\n",
    "            first_customer_time = min(customer_messages_times)\n",
    "            first_agent_time = min(agent_messages_times)\n",
    "            \n",
    "            print(f\"DEBUG: First customer time: {first_customer_time}\")\n",
    "            print(f\"DEBUG: First agent time: {first_agent_time}\")\n",
    "            \n",
    "            # Validasi: pastikan agent reply setelah customer question\n",
    "            if first_agent_time > first_customer_time:\n",
    "                lead_time_minutes = (first_agent_time - first_customer_time).total_seconds() / 60\n",
    "                print(f\"DEBUG: Calculated lead time: {lead_time_minutes} minutes\")\n",
    "                \n",
    "                # Minimum 1 minute, maksimum reasonable\n",
    "                lead_time_minutes = max(lead_time_minutes, 1.0)\n",
    "                lead_time_minutes = min(lead_time_minutes, 1440.0)  # Max 24 jam\n",
    "                \n",
    "                return lead_time_minutes\n",
    "            else:\n",
    "                # Jika agent reply sebelum customer, ini masalah timestamp\n",
    "                print(f\"‚ö†Ô∏è Timestamp issue: Agent replied before customer question\")\n",
    "                print(f\"   Customer: {first_customer_time}, Agent: {first_agent_time}\")\n",
    "                \n",
    "                # Fallback: cari agent reply pertama SETELAH customer question\n",
    "                subsequent_agents = [t for t in agent_messages_times if t > first_customer_time]\n",
    "                if subsequent_agents:\n",
    "                    first_valid_agent_time = min(subsequent_agents)\n",
    "                    lead_time_minutes = (first_valid_agent_time - first_customer_time).total_seconds() / 60\n",
    "                    lead_time_minutes = max(lead_time_minutes, 1.0)\n",
    "                    print(f\"‚úÖ Using subsequent agent reply: {lead_time_minutes} minutes\")\n",
    "                    return lead_time_minutes\n",
    "                else:\n",
    "                    # Fallback: estimate based on message order\n",
    "                    print(\"‚ö†Ô∏è Using message count fallback\")\n",
    "                    if customer_messages and agent_messages:\n",
    "                        return len(agent_messages) * 3.0\n",
    "                    \n",
    "                return 15.0  # Default fallback\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Lead time calculation error: {e}\")\n",
    "            import traceback\n",
    "            print(f\"Detailed error: {traceback.format_exc()}\")\n",
    "            return 10.0  # Fallback\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921fe3d",
   "metadata": {},
   "source": [
    "Debugging Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc100117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis untuk problematic tickets\n",
    "def debug_problematic_tickets():\n",
    "    \"\"\"Debug khusus untuk ticket yang bermasalah\"\"\"\n",
    "    if raw_df is None:\n",
    "        return\n",
    "    \n",
    "    problematic_tickets = ['18ea89910d0d8eac44aecca81d779e3a', '9842cd7eee5451283f8430fb83469940']\n",
    "    \n",
    "    print(\"üêõ DETAILED DEBUG FOR PROBLEMATIC TICKETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    parser = ConversationParser()\n",
    "    for ticket_id in problematic_tickets:\n",
    "        print(f\"\\nüîç DEBUG TICKET: {ticket_id}\")\n",
    "        ticket_df = raw_df[raw_df['Ticket Number'] == ticket_id].sort_values('parsed_timestamp')\n",
    "        \n",
    "        # Show ALL messages setelah conversation start\n",
    "        conversation_start = parser.detect_conversation_start(ticket_df)\n",
    "        \n",
    "        if conversation_start:\n",
    "            filtered_df = parser._filter_bot_messages(ticket_df)\n",
    "            filtered_df = filtered_df[filtered_df['parsed_timestamp'] >= conversation_start]\n",
    "            \n",
    "            print(f\"üìã ALL MESSAGES AFTER CONVERSATION START ({len(filtered_df)} messages):\")\n",
    "            for idx, row in filtered_df.iterrows():\n",
    "                role = row['Role']\n",
    "                message = str(row['Message'])[:80]\n",
    "                timestamp = row['parsed_timestamp']\n",
    "                is_meaningful = parser._is_meaningful_message(message)\n",
    "                meaningful_flag = \"‚úÖ\" if is_meaningful else \"‚ùå\"\n",
    "                \n",
    "                print(f\"   {meaningful_flag} {timestamp} | {role:15} | {message}...\")\n",
    "            \n",
    "            # Analyze why no Q-A pairs\n",
    "            print(f\"\\nüîé ANALYSIS:\")\n",
    "            customer_msgs = filtered_df[filtered_df['Role'].str.lower().str.contains('customer', na=False)]\n",
    "            operator_msgs = filtered_df[filtered_df['Role'].str.lower().str.contains('operator|agent', na=False)]\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Customer messages: {len(customer_msgs)}\")\n",
    "            print(f\"   ‚Ä¢ Operator messages: {len(operator_msgs)}\")\n",
    "            \n",
    "            meaningful_customer = [msg for msg in customer_msgs['Message'] if parser._is_meaningful_message(str(msg))]\n",
    "            print(f\"   ‚Ä¢ Meaningful customer messages: {len(meaningful_customer)}\")\n",
    "            \n",
    "            if len(meaningful_customer) == 0:\n",
    "                print(\"   ‚ùå REASON: No meaningful customer questions after operator greeting\")\n",
    "            elif len(operator_msgs) == 0:\n",
    "                print(\"   ‚ùå REASON: No operator responses after customer questions\")\n",
    "            else:\n",
    "                print(\"   ‚ùå REASON: Timing/sequence issues in Q-A matching\")\n",
    "\n",
    "# Run debug\n",
    "debug_problematic_tickets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3f5d3",
   "metadata": {},
   "source": [
    "Main Issue Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Issue Detector dengan Enhanced Question Detection\n",
    "class MainIssueDetector:\n",
    "    def __init__(self):\n",
    "        self.issue_keywords = {\n",
    "            'serious': [\n",
    "                'error', 'rusak', 'masalah', 'gagal', 'mogok', 'mati', 'tidak bisa', \n",
    "                'help', 'urgent', 'kendala', 'trouble', 'macet', 'hang', 'blank',\n",
    "                'not responding', 'bermasalah', 'gangguan', 'mogok', 'starter',\n",
    "                'rem blong', 'overheating', 'transmisi', 'kelistrikan', 'aki soak'\n",
    "            ],\n",
    "            'complaint': [\n",
    "                'komplain', 'kecewa', 'marah', 'protes', 'pengaduan', 'keluhan', \n",
    "                'sakit hati', 'tidak puas', 'keberatan', 'sangat kecewa', 'refund',\n",
    "                'garansi ditolak', 'pelayanan buruk', 'tidak profesional'\n",
    "            ],\n",
    "            'normal': [\n",
    "                'tanya', 'info', 'harga', 'berapa', 'cara', 'bagaimana', 'fungsi', \n",
    "                'promo', 'spesifikasi', 'fitur', 'mau tanya', 'boleh tanya', \n",
    "                'minta info', 'informasi', 'tanyakan', 'booking', 'test drive',\n",
    "                'alamat', 'lokasi', 'jam operasional', 'servis', 'sparepart'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # initial question indicators\n",
    "        self.initial_question_indicators = [\n",
    "            'mau tanya', 'boleh tanya', 'minta info', 'tanya dong', 'berapa harga',\n",
    "            'bagaimana cara', 'info', 'promo', 'spesifikasi', 'fungsi',\n",
    "            'apa', 'bagaimana', 'berapa', 'kapan', 'dimana', 'kenapa',  \n",
    "            'bisa', 'boleh', 'minta', 'tolong', 'caranya', 'gimana'    \n",
    "        ]\n",
    "        \n",
    "        # follow-up indicators \n",
    "        self.follow_up_indicators = [\n",
    "            'ok', 'oke', 'baik', 'sip', 'terima kasih', 'tks', 'thanks', 'makasih',\n",
    "            'kalau', 'jadi', 'berarti', 'apakah', 'apakah benar', 'bukan', 'oh',\n",
    "            'clarification', 'follow up', 'lanjutan' \n",
    "        ]\n",
    "    \n",
    "    def _is_initial_question(self, question):\n",
    "        \"\"\"Improved initial question detection\"\"\"\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # 1. Check explicit initial question patterns\n",
    "        if any(indicator in question_lower for indicator in self.initial_question_indicators):\n",
    "            return True\n",
    "        \n",
    "        # 2. Check jika question diawali dengan question word \n",
    "        question_words = ['apa', 'bagaimana', 'berapa', 'kapan', 'dimana', 'kenapa', 'bisa', 'boleh']\n",
    "        first_word = question_lower.split()[0] if question_lower.split() else \"\"\n",
    "        if first_word in question_words:\n",
    "            return True\n",
    "        \n",
    "        # 3. Check question mark dan meaningful content \n",
    "        has_question_mark = '?' in question_lower\n",
    "        word_count = len(question_lower.split())\n",
    "        \n",
    "        if has_question_mark and word_count >= 4 and not self._is_follow_up(question):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _is_follow_up(self, question):\n",
    "        \"\"\"Follow-up detection\"\"\"\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # 1. Check explicit follow-up patterns\n",
    "        if any(indicator in question_lower for indicator in self.follow_up_indicators):\n",
    "            return True\n",
    "        \n",
    "        # 2. Check jika question pendek dan mengandung acknowledgment\n",
    "        words = question_lower.split()\n",
    "        acknowledgment_words = ['ok', 'oke', 'baik', 'sip', 'tks', 'thanks']\n",
    "        \n",
    "        if len(words) <= 3 and any(word in acknowledgment_words for word in words):\n",
    "            return True\n",
    "        \n",
    "        # 3. Check clarification patterns\n",
    "        clarification_indicators = ['berarti', 'jadi', 'bukan', 'oh', 'apakah benar']\n",
    "        if any(indicator in question_lower for indicator in clarification_indicators):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def detect_main_issue(self, qa_pairs):\n",
    "        \"\"\"Deteksi main issue dari Q-A pairs - IMPROVED\"\"\"\n",
    "        if not qa_pairs:\n",
    "            return None\n",
    "        \n",
    "        scored_issues = []\n",
    "        \n",
    "        for i, pair in enumerate(qa_pairs):\n",
    "            if not pair['is_answered']:\n",
    "                continue\n",
    "                \n",
    "            question = pair['question'].lower()\n",
    "            score = 0\n",
    "            \n",
    "            # 1. Keyword-based scoring \n",
    "            complaint_matches = sum(1 for kw in self.issue_keywords['complaint'] if kw in question)\n",
    "            serious_matches = sum(1 for kw in self.issue_keywords['serious'] if kw in question) \n",
    "            normal_matches = sum(1 for kw in self.issue_keywords['normal'] if kw in question)\n",
    "            \n",
    "            # Weighted scoring - complaint > serious > normal\n",
    "            score += (complaint_matches * 3) + (serious_matches * 2) + (normal_matches * 1)\n",
    "            \n",
    "            # 2. Question type analysis \n",
    "            is_initial_question = self._is_initial_question(pair['question'])  \n",
    "            is_follow_up = self._is_follow_up(pair['question'])  \n",
    "            \n",
    "            if is_initial_question and not is_follow_up:\n",
    "                score += 3  # Strong bonus untuk initial question\n",
    "            elif is_follow_up and not is_initial_question:\n",
    "                score -= 2  # Penalty untuk follow-up/clarification questions\n",
    "            \n",
    "            # 3. Position scoring \n",
    "            if i == 0:  # First question\n",
    "                score += 2\n",
    "            elif i == 1:  # Second question  \n",
    "                score += 1\n",
    "            \n",
    "            # 4. Content quality scoring \n",
    "            # Question yang lebih panjang dan detailed biasanya lebih important\n",
    "            word_count = len(question.split())\n",
    "            if word_count > 8:\n",
    "                score += 1\n",
    "            elif word_count < 4:\n",
    "                score -= 1\n",
    "            \n",
    "            # 5. Lead time consideration \n",
    "            # Questions dengan lead time sangat panjang mungkin important\n",
    "            lead_time = pair.get('lead_time_minutes', 0)\n",
    "            if lead_time > 15:  # Lebih dari 15 menit\n",
    "                score += 1\n",
    "            \n",
    "            scored_issues.append({\n",
    "                'question': pair['question'],\n",
    "                'question_time': pair['question_time'],\n",
    "                'score': max(score, 0),  \n",
    "                'position': i,\n",
    "                'lead_time': lead_time,\n",
    "                'bubble_count': pair.get('bubble_count', 1),\n",
    "                'word_count': word_count,\n",
    "                'is_initial_question': is_initial_question,\n",
    "                'is_follow_up': is_follow_up,\n",
    "                'complaint_matches': complaint_matches,\n",
    "                'serious_matches': serious_matches, \n",
    "                'normal_matches': normal_matches,\n",
    "                'pair_data': pair\n",
    "            })\n",
    "        \n",
    "        if not scored_issues:\n",
    "            return None\n",
    "        \n",
    "        # Pilih question dengan score tertinggi\n",
    "        main_issue = max(scored_issues, key=lambda x: x['score'])\n",
    "        \n",
    "        # IMPROVED issue type determination\n",
    "        if main_issue['complaint_matches'] > 0:\n",
    "            issue_type = 'complaint'\n",
    "        elif main_issue['serious_matches'] > 0:\n",
    "            issue_type = 'serious'\n",
    "        elif main_issue['normal_matches'] > 0:\n",
    "            issue_type = 'normal'\n",
    "        else:\n",
    "            # Fallback based on score\n",
    "            if main_issue['score'] >= 5:\n",
    "                issue_type = 'complaint'\n",
    "            elif main_issue['score'] >= 3:\n",
    "                issue_type = 'serious'\n",
    "            else:\n",
    "                issue_type = 'normal'\n",
    "        \n",
    "        # Build detailed reason\n",
    "        reason_parts = []\n",
    "        if main_issue['is_initial_question']:\n",
    "            reason_parts.append(\"initial question\")\n",
    "        if main_issue['complaint_matches'] > 0:\n",
    "            reason_parts.append(f\"{main_issue['complaint_matches']} complaint keywords\")\n",
    "        if main_issue['serious_matches'] > 0:\n",
    "            reason_parts.append(f\"{main_issue['serious_matches']} serious keywords\") \n",
    "        if main_issue['normal_matches'] > 0:\n",
    "            reason_parts.append(f\"{main_issue['normal_matches']} normal keywords\")\n",
    "        if main_issue['position'] == 0:\n",
    "            reason_parts.append(\"first question\")\n",
    "        \n",
    "        reason = f\"Score: {main_issue['score']} ({', '.join(reason_parts)})\"\n",
    "        \n",
    "        return {\n",
    "            'question': main_issue['question'],\n",
    "            'question_time': main_issue['question_time'],\n",
    "            'issue_type': issue_type,\n",
    "            'confidence_score': min(main_issue['score'] / 10.0, 1.0),\n",
    "            'all_candidates': scored_issues,\n",
    "            'selected_reason': reason,\n",
    "            'scoring_details': {\n",
    "                'complaint_matches': main_issue['complaint_matches'],\n",
    "                'serious_matches': main_issue['serious_matches'],\n",
    "                'normal_matches': main_issue['normal_matches'],\n",
    "                'is_initial_question': main_issue['is_initial_question'],\n",
    "                'is_follow_up': main_issue['is_follow_up']\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def debug_scoring(self, qa_pairs):\n",
    "        \"\"\"Debug function untuk melihat detailed scoring\"\"\"\n",
    "        if not qa_pairs:\n",
    "            return\n",
    "        \n",
    "        main_issue = self.detect_main_issue(qa_pairs)\n",
    "        \n",
    "        print(\"üîç DETAILED SCORING ANALYSIS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, candidate in enumerate(main_issue['all_candidates']):\n",
    "            print(f\"\\n{i+1}. '{candidate['question'][:60]}...'\")\n",
    "            print(f\"   Score: {candidate['score']}\")\n",
    "            print(f\"   Position: {candidate['position'] + 1}\")\n",
    "            print(f\"   Word Count: {candidate['word_count']}\")\n",
    "            print(f\"   Initial Question: {candidate['is_initial_question']}\")\n",
    "            print(f\"   Follow-up: {candidate['is_follow_up']}\")\n",
    "            print(f\"   Keywords: C:{candidate['complaint_matches']} S:{candidate['serious_matches']} N:{candidate['normal_matches']}\")\n",
    "            print(f\"   Lead Time: {candidate['lead_time']} min\")\n",
    "\n",
    "# Test dengan improved detector\n",
    "detector = MainIssueDetector()\n",
    "\n",
    "parser = ConversationParser()\n",
    "if 'parser' in locals() and raw_df is not None:\n",
    "    sample_ticket_id = 'ead8d44e4914399b76af974a5169856e'\n",
    "    ticket_df = raw_df[raw_df['Ticket Number'] == sample_ticket_id]\n",
    "    qa_pairs = parser.parse_conversation(ticket_df)\n",
    "    \n",
    "    if qa_pairs:\n",
    "        print(\"üéØ ENHANCED MAIN ISSUE DETECTION:\")\n",
    "        main_issue = detector.detect_main_issue(qa_pairs)\n",
    "        print(f\"   Selected: '{main_issue['question'][:80]}...'\")\n",
    "        print(f\"   Type: {main_issue['issue_type']}\")\n",
    "        print(f\"   Confidence: {main_issue['confidence_score']:.2f}\")\n",
    "        print(f\"   Reason: {main_issue['selected_reason']}\")\n",
    "        \n",
    "        # Show scoring details\n",
    "        print(f\"\\nüìä Scoring Details:\")\n",
    "        details = main_issue['scoring_details']\n",
    "        print(f\"   Complaint Keywords: {details['complaint_matches']}\")\n",
    "        print(f\"   Serious Keywords: {details['serious_matches']}\")\n",
    "        print(f\"   Normal Keywords: {details['normal_matches']}\")\n",
    "        print(f\"   Initial Question: {details['is_initial_question']}\")\n",
    "        print(f\"   Follow-up: {details['is_follow_up']}\")\n",
    "        \n",
    "        # Debug scoring\n",
    "        detector.debug_scoring(qa_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e0a13",
   "metadata": {},
   "source": [
    "Hybrid ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid ML Classifier\n",
    "class HybridClassifier:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,  # REDUCE features\n",
    "            ngram_range=(1, 1),  # Start with unigrams saja\n",
    "            min_df=1,           # Less restrictive\n",
    "            max_df=0.9,\n",
    "            stop_words=None     # Jangan remove stop words, penting untuk context\n",
    "        )\n",
    "        self.classifier = LogisticRegression(\n",
    "            random_state=config.RANDOM_STATE,\n",
    "            max_iter=2000,      # More iterations\n",
    "            class_weight='balanced',\n",
    "            C=1.0              # Regularization\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        \n",
    "        # Enhanced rule-based fallback\n",
    "        self.rule_keywords = {\n",
    "            'complaint': [\n",
    "                'komplain', 'kecewa', 'marah', 'protes', 'pengaduan', 'keluhan', \n",
    "                'sakit hati', 'tidak puas', 'keberatan', 'sangat kecewa', 'refund',\n",
    "                'garansi ditolak', 'pelayanan buruk', 'tidak profesional', 'minta uang kembali'\n",
    "            ],\n",
    "            'serious': [\n",
    "                'error', 'rusak', 'masalah', 'gagal', 'mogok', 'mati', 'tidak bisa', \n",
    "                'help', 'urgent', 'kendala', 'trouble', 'macet', 'hang', 'blank',\n",
    "                'not responding', 'bermasalah', 'gangguan', 'starter', 'rem blong', \n",
    "                'overheating', 'transmisi', 'kelistrikan', 'aki soak', 'check engine'\n",
    "            ],\n",
    "            'normal': [\n",
    "                'tanya', 'info', 'harga', 'berapa', 'cara', 'bagaimana', 'fungsi', \n",
    "                'promo', 'spesifikasi', 'fitur', 'mau tanya', 'boleh tanya', \n",
    "                'minta info', 'informasi', 'tanyakan', 'booking', 'test drive',\n",
    "                'alamat', 'lokasi', 'jam operasional', 'servis', 'sparepart', 'dp'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        self.high_confidence_threshold = 0.7\n",
    "        self.medium_confidence_threshold = 0.5\n",
    "        \n",
    "        print(\"‚úÖ Hybrid Classifier initialized\")\n",
    "    \n",
    "    def create_enhanced_training_data(self):\n",
    "        \"\"\"Create BETTER training data dengan lebih banyak samples dan balance\"\"\"\n",
    "        enhanced_data = {\n",
    "            'texts': [\n",
    "                \"mau tanya harga mobil avanza berapa?\",\n",
    "                \"berapa harga toyota rush terbaru?\",\n",
    "                \"info promo innova zenix terbaru\",\n",
    "                \"bagaimana cara booking test drive?\",\n",
    "                \"spesifikasi toyota fortuner lengkap\",\n",
    "                \"alamat dealer terdekat di jakarta\",\n",
    "                \"jam operasional bengkel toyota\",\n",
    "                \"berapa biaya servis berkala avanza?\",\n",
    "                \"cara aktivasi fitur t-intouch\",\n",
    "                \"fungsi safety sense pada mobil\",\n",
    "                \"minta info dp ringan kredit\",\n",
    "                \"berapa lama waktu servis berkala?\",\n",
    "                \"warna yang tersedia untuk calya\",\n",
    "                \"beda innova zenix dan innova lama\",\n",
    "                \"fasilitas di bengkel toyota\",\n",
    "                \"syarat test drive mobil baru\",\n",
    "                \"info asuransi mobil terbaik\",\n",
    "                \"cara klaim garansi mobil\",\n",
    "                \"berapa harga velg ori innova?\",\n",
    "                \"lokasi dealer 24 jam\",\n",
    "                \"info cicilan mobil tanpa dp\",\n",
    "                \"berapa konsumsi bensin avanza?\",\n",
    "                \"sparepart yang perlu diganti rutin\",\n",
    "                \"cara perawatan mobil baru\",\n",
    "                \"beda vvti dan d4d\",\n",
    "                \"berapa harga oli mesin ori?\",\n",
    "                \"jadwal service gratis pertama\",\n",
    "                \"cara connect android auto\",\n",
    "                \"info membership toyota\",\n",
    "                \"berapa harga ban mobil avanza\",\n",
    "                \n",
    "                \"mobil saya error tidak bisa starter\",\n",
    "                \"mesin bunyi aneh ada masalah serius\",\n",
    "                \"aplikasi error terus tidak bisa login\",\n",
    "                \"rem blong sangat berbahaya\",\n",
    "                \"mogok di jalan butuh bantuan cepat\",\n",
    "                \"mesin overheating terus menerus\",\n",
    "                \"transmisi bermasalah tidak bisa pindah gigi\",\n",
    "                \"kelistrikan error semua lampu mati\",\n",
    "                \"aki soak tidak bisa starter pagi ini\",\n",
    "                \"check engine menyala terus sejak kemarin\",\n",
    "                \"mobil tiba-tiba mati di tol\",\n",
    "                \"asap keluar dari kap mesin\",\n",
    "                \"rem tidak berfungsi dengan baik\",\n",
    "                \"setir berat sekali tidak bisa dibelokkan\",\n",
    "                \"oli mesin bocor parah\",\n",
    "                \"air radiator habis terus menerus\",\n",
    "                \"mobil tidak bisa distarter sama sekali\",\n",
    "                \"lampu dashboard berkedip semua\",\n",
    "                \"ban pecah di jalan tol\",\n",
    "                \"mesin bergetar sangat kencang\",\n",
    "                \"kopling slip tidak bisa jalan\",\n",
    "                \"ac tidak dingin sama sekali\",\n",
    "                \"rem bunyi keras setiap kali diinjak\",\n",
    "                \"mobil tidak bisa masuk gigi\",\n",
    "                \"asap hitam keluar dari knalpot\",\n",
    "                \"mesin sulit dinyakan di pagi hari\",\n",
    "                \"rem tangan tidak bisa dilepas\",\n",
    "                \"oli terus berkurang setiap hari\",\n",
    "                \"mobil terbakar sendiri\",\n",
    "                \"kaca spion patah karena kecelakaan\",\n",
    "                \n",
    "                \"saya komplain tentang pelayanan bengkel\",\n",
    "                \"sangat kecewa dengan produk toyota ini\",\n",
    "                \"komplain untuk garansi yang ditolak\",\n",
    "                \"pelayanan customer service sangat buruk\",\n",
    "                \"minta refund untuk produk cacat\",\n",
    "                \"protes untuk biaya servis yang mahal\",\n",
    "                \"pengaduan untuk teknisi tidak profesional\",\n",
    "                \"kecewa dengan waiting time yang lama\",\n",
    "                \"komplain sparepart palsu yang dipasang\",\n",
    "                \"protes untuk janji tidak ditepati\",\n",
    "                \"saya marah dengan kualitas servis\",\n",
    "                \"komplain mobil baru langsung rusak\",\n",
    "                \"kecewa dengan respon yang lambat\",\n",
    "                \"minta ganti rugi untuk kerusakan\",\n",
    "                \"protes harga sparepart terlalu mahal\",\n",
    "                \"komplain untuk janji service tidak tepat waktu\",\n",
    "                \"sangat tidak puas dengan pelayanan\",\n",
    "                \"komplain mobil sering masuk bengkel\",\n",
    "                \"kecewa dengan kualitas cat mobil\",\n",
    "                \"protes untuk penanganan yang lamban\",\n",
    "                \"komplain untuk informasi yang misleading\",\n",
    "                \"saya keberatan dengan biaya tambahan\",\n",
    "                \"komplain untuk attitude staff yang kasar\",\n",
    "                \"kecewa dengan fitur yang tidak berfungsi\",\n",
    "                \"protes untuk kebijakan yang tidak jelas\",\n",
    "                \"komplain untuk janji telepon tidak ditepati\",\n",
    "                \"sangat marah dengan pelayanan after sales\",\n",
    "                \"komplain untuk sparepart tidak tersedia\",\n",
    "                \"kecewa dengan waktu tunggu yang panjang\",\n",
    "                \"protes untuk solusi yang tidak memuaskan\"\n",
    "            ],\n",
    "            'labels': ['normal'] * 30 + ['serious'] * 30 + ['complaint'] * 30\n",
    "        }\n",
    "        \n",
    "        return enhanced_data\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"Train model dengan enhanced approach\"\"\"\n",
    "        try:\n",
    "            print(\"ü§ñ Training Enhanced ML model...\")\n",
    "            print(f\"   Training samples: {len(X_train)}\")\n",
    "            print(f\"   Class distribution: {Counter(y_train)}\")\n",
    "            \n",
    "            # Fit vectorizer dan transform data\n",
    "            X_vec = self.vectorizer.fit_transform(X_train)\n",
    "            \n",
    "            # Train classifier\n",
    "            self.classifier.fit(X_vec, y_train)\n",
    "            self.is_trained = True\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            train_pred = self.classifier.predict(X_vec)\n",
    "            train_accuracy = accuracy_score(y_train, train_pred)\n",
    "            \n",
    "            # Save model\n",
    "            joblib.dump(self.vectorizer, f\"{config.MODEL_SAVE_PATH}/vectorizer.pkl\")\n",
    "            joblib.dump(self.classifier, f\"{config.MODEL_SAVE_PATH}/classifier.pkl\")\n",
    "            \n",
    "            print(f\"‚úÖ Model trained - Accuracy: {train_accuracy:.3f}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Predict dengan hybrid approach\"\"\"\n",
    "        if not text or len(text.strip()) < 3:\n",
    "            return 'normal', 0.5\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Step 1: Try ML prediction jika model sudah trained\n",
    "        ml_prediction, ml_confidence = None, 0.0\n",
    "        if self.is_trained:\n",
    "            try:\n",
    "                X_vec = self.vectorizer.transform([text])\n",
    "                ml_prediction = self.classifier.predict(X_vec)[0]\n",
    "                ml_probs = self.classifier.predict_proba(X_vec)[0]\n",
    "                ml_confidence = np.max(ml_probs)\n",
    "                \n",
    "                # High confidence ML prediction\n",
    "                if ml_confidence >= self.high_confidence_threshold:\n",
    "                    return ml_prediction, ml_confidence\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è ML prediction failed: {e}\")\n",
    "        \n",
    "        # Step 2: Rule-based prediction\n",
    "        rule_prediction = self._rule_based_predict(text_lower)\n",
    "        rule_confidence = self._calculate_rule_confidence(text_lower, rule_prediction)\n",
    "        \n",
    "        # Step 3: Hybrid decision making\n",
    "        if self.is_trained and ml_prediction:\n",
    "            if ml_confidence >= self.medium_confidence_threshold:\n",
    "                if ml_prediction == rule_prediction:\n",
    "                    hybrid_confidence = (ml_confidence + rule_confidence) / 2\n",
    "                    return ml_prediction, hybrid_confidence\n",
    "                else:\n",
    "                    # Conflict - prefer rules untuk safety\n",
    "                    return rule_prediction, rule_confidence * 0.8\n",
    "            else:\n",
    "                return rule_prediction, rule_confidence\n",
    "        else:\n",
    "            return rule_prediction, rule_confidence\n",
    "    \n",
    "    def _rule_based_predict(self, text_lower):\n",
    "        \"\"\"Rule-based classification fallback\"\"\"\n",
    "        scores = {'normal': 0, 'serious': 0, 'complaint': 0}\n",
    "        \n",
    "        for category, keywords in self.rule_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in text_lower:\n",
    "                    if category == 'complaint':\n",
    "                        scores[category] += 3\n",
    "                    elif category == 'serious':\n",
    "                        scores[category] += 2\n",
    "                    else:\n",
    "                        scores[category] += 1\n",
    "        \n",
    "        max_score = max(scores.values())\n",
    "        if max_score == 0:\n",
    "            return 'normal'\n",
    "        \n",
    "        max_categories = [cat for cat, score in scores.items() if score == max_score]\n",
    "        if len(max_categories) > 1:\n",
    "            if 'serious' in max_categories:\n",
    "                return 'serious'\n",
    "            elif 'complaint' in max_categories:\n",
    "                return 'complaint'\n",
    "            else:\n",
    "                return 'normal'\n",
    "        \n",
    "        return max_categories[0]\n",
    "    \n",
    "    def _calculate_rule_confidence(self, text_lower, predicted_category):\n",
    "        \"\"\"Calculate confidence score untuk rule-based prediction\"\"\"\n",
    "        scores = {'normal': 0, 'serious': 0, 'complaint': 0}\n",
    "        total_weight = 0\n",
    "        \n",
    "        for category, keywords in self.rule_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in text_lower:\n",
    "                    weight = 3 if category == 'complaint' else (2 if category == 'serious' else 1)\n",
    "                    scores[category] += weight\n",
    "                    total_weight += weight\n",
    "        \n",
    "        if total_weight == 0:\n",
    "            return 0.5\n",
    "        \n",
    "        max_score = max(scores.values())\n",
    "        confidence = max_score / total_weight\n",
    "        \n",
    "        sorted_scores = sorted(scores.values(), reverse=True)\n",
    "        if len(sorted_scores) > 1 and sorted_scores[0] > sorted_scores[1] * 2:\n",
    "            confidence = min(confidence * 1.2, 0.95)\n",
    "        \n",
    "        return confidence\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"Evaluate model performance dengan detailed report\"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"‚ùå Model not trained\")\n",
    "            return None\n",
    "        \n",
    "        X_vec = self.vectorizer.transform(X_test)\n",
    "        y_pred = self.classifier.predict(X_vec)\n",
    "        y_pred_proba = self.classifier.predict_proba(X_vec)\n",
    "        \n",
    "        print(\"üìä ENHANCED CLASSIFIER PERFORMANCE REPORT\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"Test Samples: {len(X_test)}\")\n",
    "        print(f\"Class Distribution: {Counter(y_test)}\")\n",
    "        \n",
    "        print(\"\\nüìà Detailed Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['normal', 'serious', 'complaint']))\n",
    "        \n",
    "        max_confidences = np.max(y_pred_proba, axis=1)\n",
    "        print(f\"\\nüéØ Confidence Analysis:\")\n",
    "        print(f\"   Average Confidence: {np.mean(max_confidences):.3f}\")\n",
    "        print(f\"   High Confidence (>0.7): {np.sum(max_confidences > 0.7)}/{len(max_confidences)}\")\n",
    "        print(f\"   Low Confidence (<0.5): {np.sum(max_confidences < 0.5)}/{len(max_confidences)}\")\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['normal', 'serious', 'complaint'],\n",
    "                   yticklabels=['normal', 'serious', 'complaint'])\n",
    "        plt.title('Confusion Matrix - Enhanced Classifier')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Feature importance\n",
    "        self._show_feature_importance()\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def _show_feature_importance(self, top_n=15):\n",
    "        \"\"\"Show most important features untuk setiap class\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return\n",
    "        \n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"\\nüîç Top {top_n} Features per Class:\")\n",
    "        \n",
    "        for i, class_name in enumerate(['normal', 'serious', 'complaint']):\n",
    "            coef = self.classifier.coef_[i]\n",
    "            top_indices = np.argsort(coef)[-top_n:][::-1]\n",
    "            top_features = [(feature_names[idx], coef[idx]) for idx in top_indices]\n",
    "            \n",
    "            print(f\"\\n{class_name.upper()}:\")\n",
    "            for feature, score in top_features:\n",
    "                print(f\"   {feature}: {score:.3f}\")\n",
    "\n",
    "# Initialize enhanced classifier\n",
    "classifier = HybridClassifier()\n",
    "\n",
    "# Test dengan enhanced classifier\n",
    "print(\"üß™ TESTING ENHANCED CLASSIFIER\")\n",
    "\n",
    "test_samples = [\n",
    "    \"mobil saya error tidak bisa starter, mogok di jalan\",\n",
    "    \"saya komplain tentang pelayanan bengkel yang sangat buruk\",\n",
    "    \"mau tanya harga toyota avanza berapa?\",\n",
    "    \"aplikasi error terus tidak bisa login sudah 3 hari\",\n",
    "    \"saya kecewa dengan produk ini, minta refund\",\n",
    "    \"bagaimana cara aktivasi fitur t-intouch?\",\n",
    "    \"mesin bunyi aneh ada masalah serius\",\n",
    "    \"info promo terbaru untuk innova zenix\"\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Enhanced Prediction Results:\")\n",
    "for text in test_samples:\n",
    "    prediction, confidence = classifier.predict(text)\n",
    "    print(f\"   '{text[:40]}...' ‚Üí {prediction} (conf: {confidence:.2f})\")\n",
    "\n",
    "# Create ENHANCED training data\n",
    "print(\"\\nü§ñ CREATING ENHANCED TRAINING DATA...\")\n",
    "enhanced_data = classifier.create_enhanced_training_data()\n",
    "\n",
    "# Split data dengan lebih banyak samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    enhanced_data['texts'], \n",
    "    enhanced_data['labels'],\n",
    "    test_size=0.2,  # 20% test size\n",
    "    random_state=config.RANDOM_STATE,\n",
    "    stratify=enhanced_data['labels']\n",
    ")\n",
    "\n",
    "print(f\"üìä Enhanced Training Data: {len(X_train)} samples\")\n",
    "print(f\"üìä Enhanced Test Data: {len(X_test)} samples\")\n",
    "print(f\"üìä Class Distribution - Train: {Counter(y_train)}\")\n",
    "print(f\"üìä Class Distribution - Test: {Counter(y_test)}\")\n",
    "\n",
    "# Train the enhanced model\n",
    "success = classifier.train(X_train, y_train)\n",
    "\n",
    "if success:\n",
    "    # Evaluate enhanced model\n",
    "    accuracy = classifier.evaluate_model(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ENHANCED HYBRID CLASSIFIER READY!\")\n",
    "    print(f\"   Model Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   Training Samples: {len(X_train)}\")\n",
    "    print(f\"   Test Samples: {len(X_test)}\")\n",
    "    print(f\"   Rule-based Fallback: Active\")\n",
    "else:\n",
    "    print(\"‚ùå Enhanced model training failed, using rule-based only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d35453",
   "metadata": {},
   "source": [
    "Reply Analyzer & Lead Time Calculator (WITH BERT INTEGRATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7 - COMPLETELY FIXED Reply Analyzer sesuai requirement\n",
    "class ReplyAnalyzer:\n",
    "    def __init__(self):\n",
    "        # First reply indicators - HARUS meaningful acknowledgment\n",
    "        self.first_reply_indicators = [\n",
    "            'kami cek', 'kami proses', 'akan kami', 'pengecekan', 'verifikasi', \n",
    "            'kami bantu', 'kami teruskan', 'kami diskusikan', 'cek dulu',\n",
    "            'proses dulu', 'tunggu sebentar', 'mohon ditunggu', 'akan kami proses',\n",
    "            'sedang kami cek', 'kami lihat', 'kami periksa', 'konfirmasi'\n",
    "        ]\n",
    "        \n",
    "        # Final reply indicators - HARUS memberikan solusi/informasi\n",
    "        self.final_reply_indicators = [\n",
    "            'bisa menghubungi', 'silakan menghubungi', 'disarankan untuk',\n",
    "            'berikut informasi', 'nomor telepon', 'alamat dealer', 'bengkel resmi',\n",
    "            'jawabannya adalah', 'solusinya', 'bisa dilakukan', 'prosedurnya',\n",
    "            'caranya', 'merupakan', 'adalah', 'harga mulai', 'biaya required',\n",
    "            'tarif berlaku', 'jam operasional', 'alamat lengkap', 'spesifikasi',\n",
    "            'fungsi', 'harga', 'biaya', 'tarif', 'promo', 'diskon', 'cara booking'\n",
    "        ]\n",
    "        \n",
    "        # Conversation patterns to SKIP (bukan first/final reply)\n",
    "        self.skip_patterns = [\n",
    "            'terima kasih telah menghubungi', 'selamat datang', 'dengan senang hati',\n",
    "            'ada yang bisa dibantu', 'bisa dibantu', 'boleh dibantu', \n",
    "            'halo bapak/ibu', 'perkenalkan', 'dengan saya', 'virtual assistant',\n",
    "            'silakan memilih', 'pilih menu', 'apa lagi yang bisa dibantu',\n",
    "            'apakah sudah jelas', 'apakah cukup', 'apakah membantu',\n",
    "            'baik', 'silahkan', 'silakan', 'terima kasih', 'thanks', 'makasih'\n",
    "        ]\n",
    "        \n",
    "        # Conversation enders (bukan final reply yang meaningful)\n",
    "        self.conversation_enders = [\n",
    "            'terima kasih', 'thanks', 'makasih', 'tks', 'sampai jumpa',\n",
    "            'semoga membantu', 'selamat', 'goodbye', 'bye', 'dadah'\n",
    "        ]\n",
    "        \n",
    "        # Time thresholds\n",
    "        self.time_thresholds = {\n",
    "            'normal_final': 5,\n",
    "            'serious_first': 5,\n",
    "            'serious_final': 480,\n",
    "            'complaint_first': 5, \n",
    "            'complaint_final': 7200\n",
    "        }\n",
    "\n",
    "    def analyze_replies(self, qa_pairs, main_issue_type):\n",
    "        \"\"\"Analyze replies dengan logic yang sesuai requirement - COMPLETELY FIXED\"\"\"\n",
    "        if not qa_pairs:\n",
    "            return None, None, self._create_empty_analysis(main_issue_type, \"No Q-A pairs available\")\n",
    "        \n",
    "        print(f\"üîç Analyzing replies for {main_issue_type} issue...\")\n",
    "        \n",
    "        # Cari first reply dan final reply dengan logic yang benar\n",
    "        first_reply = self._find_proper_first_reply(qa_pairs, main_issue_type)\n",
    "        final_reply = self._find_proper_final_reply(qa_pairs, main_issue_type, first_reply)\n",
    "        \n",
    "        # Validasi berdasarkan requirement\n",
    "        validation = self._validate_replies(first_reply, final_reply, main_issue_type, qa_pairs)\n",
    "        \n",
    "        # Calculate lead times\n",
    "        lead_times = self._calculate_lead_times(qa_pairs, first_reply, final_reply, main_issue_type)\n",
    "        \n",
    "        # Performance analysis\n",
    "        performance_analysis = self._analyze_performance(lead_times, main_issue_type)\n",
    "        \n",
    "        analysis_result = {\n",
    "            'issue_type': main_issue_type,\n",
    "            'first_reply': first_reply,\n",
    "            'final_reply': final_reply,\n",
    "            'lead_times': lead_times,\n",
    "            'reply_validation': validation,\n",
    "            'performance_analysis': performance_analysis,\n",
    "            'threshold_checks': self._check_thresholds(lead_times, main_issue_type),\n",
    "            'quality_assessment': self._assess_quality(first_reply, final_reply, main_issue_type)\n",
    "        }\n",
    "        \n",
    "        return first_reply, final_reply, analysis_result\n",
    "    \n",
    "    def _find_proper_first_reply(self, qa_pairs, issue_type):\n",
    "        \"\"\"Temukan FIRST REPLY yang meaningful - FIXED LOGIC\"\"\"\n",
    "        print(f\"   üîç Looking for FIRST reply for {issue_type} issue...\")\n",
    "        \n",
    "        for i, pair in enumerate(qa_pairs):\n",
    "            if pair['is_answered']:\n",
    "                answer = pair['answer']\n",
    "                \n",
    "                # SKIP yang jelas bukan first reply\n",
    "                if self._should_skip_as_first_reply(answer):\n",
    "                    print(f\"      ‚è© Skipping: '{answer[:50]}...' (not a proper first reply)\")\n",
    "                    continue\n",
    "                \n",
    "                # Untuk SERIOUS/COMPLAINT: cari yang mengandung first reply indicators\n",
    "                if issue_type in ['serious', 'complaint']:\n",
    "                    if self._contains_first_reply_indicators(answer):\n",
    "                        print(f\"      ‚úÖ Found FIRST reply: '{answer[:50]}...'\")\n",
    "                        return self._create_reply_object(pair, 'first_proper')\n",
    "                \n",
    "                # Untuk NORMAL: bisa ambil jawaban pertama yang meaningful\n",
    "                else:\n",
    "                    if self._is_meaningful_reply(answer) and not self._is_conversation_ender(answer):\n",
    "                        print(f\"      ‚úÖ Found FIRST reply for normal: '{answer[:50]}...'\")\n",
    "                        return self._create_reply_object(pair, 'first_normal')\n",
    "        \n",
    "        print(f\"      ‚ùå No proper FIRST reply found for {issue_type}\")\n",
    "        return None\n",
    "    \n",
    "    def _find_proper_final_reply(self, qa_pairs, issue_type, first_reply):\n",
    "        \"\"\"Temukan FINAL REPLY yang meaningful - FIXED LOGIC\"\"\"\n",
    "        print(f\"   üîç Looking for FINAL reply for {issue_type} issue...\")\n",
    "        \n",
    "        # Untuk NORMAL: final reply adalah jawaban yang meaningful\n",
    "        if issue_type == 'normal':\n",
    "            for i, pair in enumerate(reversed(qa_pairs)):  # Cari dari akhir\n",
    "                if pair['is_answered'] and self._is_meaningful_final_reply(pair['answer']):\n",
    "                    # Pastikan bukan first reply yang sama\n",
    "                    if first_reply and pair['answer_time'] == first_reply['timestamp']:\n",
    "                        continue\n",
    "                    print(f\"      ‚úÖ Found FINAL reply: '{pair['answer'][:50]}...'\")\n",
    "                    return self._create_reply_object(pair, 'final_proper')\n",
    "        \n",
    "        # Untuk SERIOUS/COMPLAINT: cari yang memberikan solusi\n",
    "        else:\n",
    "            for i, pair in enumerate(reversed(qa_pairs)):\n",
    "                if pair['is_answered'] and self._contains_final_reply_indicators(pair['answer']):\n",
    "                    # Pastikan bukan first reply yang sama\n",
    "                    if first_reply and pair['answer_time'] == first_reply['timestamp']:\n",
    "                        continue\n",
    "                    print(f\"      ‚úÖ Found FINAL reply: '{pair['answer'][:50]}...'\")\n",
    "                    return self._create_reply_object(pair, 'final_proper')\n",
    "        \n",
    "        # Fallback: cari jawaban terakhir yang meaningful\n",
    "        for i, pair in enumerate(reversed(qa_pairs)):\n",
    "            if pair['is_answered'] and self._is_meaningful_reply(pair['answer']):\n",
    "                if first_reply and pair['answer_time'] == first_reply['timestamp']:\n",
    "                    continue\n",
    "                print(f\"      ‚ö†Ô∏è Using fallback FINAL reply: '{pair['answer'][:50]}...'\")\n",
    "                return self._create_reply_object(pair, 'final_fallback')\n",
    "        \n",
    "        print(f\"      ‚ùå No proper FINAL reply found for {issue_type}\")\n",
    "        return None\n",
    "    \n",
    "    def _should_skip_as_first_reply(self, message):\n",
    "        \"\"\"Skip messages yang jelas bukan first reply\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        # Skip greetings dan generic messages\n",
    "        if any(pattern in message_lower for pattern in self.skip_patterns):\n",
    "            return True\n",
    "        \n",
    "        # Skip conversation enders\n",
    "        if self._is_conversation_ender(message):\n",
    "            return True\n",
    "            \n",
    "        # Skip messages yang terlalu pendek dan tidak meaningful\n",
    "        if len(message_lower.split()) < 3:\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def _contains_first_reply_indicators(self, message):\n",
    "        \"\"\"Cek apakah message mengandung first reply indicators\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        return any(indicator in message_lower for indicator in self.first_reply_indicators)\n",
    "    \n",
    "    def _contains_final_reply_indicators(self, message):\n",
    "        \"\"\"Cek apakah message mengandung final reply indicators\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        return any(indicator in message_lower for indicator in self.final_reply_indicators)\n",
    "    \n",
    "    def _is_meaningful_reply(self, message):\n",
    "        \"\"\"Cek apakah reply meaningful (bukan greeting/ender)\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        if self._should_skip_as_first_reply(message):\n",
    "            return False\n",
    "            \n",
    "        # Minimal panjang tertentu\n",
    "        if len(message_lower.split()) < 4:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def _is_meaningful_final_reply(self, message):\n",
    "        \"\"\"Cek apakah reply bisa dianggap sebagai final reply\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        if not self._is_meaningful_reply(message):\n",
    "            return False\n",
    "            \n",
    "        # Harus mengandung informasi/solusi, bukan sekadar acknowledgment\n",
    "        if any(word in message_lower for word in ['cek', 'proses', 'tunggu', 'konfirmasi']):\n",
    "            return False  # Ini lebih cocok sebagai first reply\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def _is_conversation_ender(self, message):\n",
    "        \"\"\"Cek apakah message adalah conversation ender\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        return any(ender in message_lower for ender in self.conversation_enders)\n",
    "    \n",
    "    def _validate_replies(self, first_reply, final_reply, issue_type, qa_pairs):\n",
    "        \"\"\"Validasi replies berdasarkan requirement - FIXED\"\"\"\n",
    "        validation = {\n",
    "            'first_reply_found': first_reply is not None,\n",
    "            'final_reply_found': final_reply is not None,\n",
    "            'recommendation': '',\n",
    "            'missing_elements': [],\n",
    "            'quality_score': 0,\n",
    "            'quality_rating': 'poor',\n",
    "            'validation_details': []\n",
    "        }\n",
    "        \n",
    "        details = []\n",
    "        \n",
    "        # Requirement: Untuk SERIOUS/COMPLAINT harus ada FIRST reply\n",
    "        if issue_type in ['serious', 'complaint']:\n",
    "            if not first_reply:\n",
    "                validation['missing_elements'].append('first_reply')\n",
    "                details.append(\"‚ùå FIRST reply missing for serious/complaint issue\")\n",
    "            elif not self._contains_first_reply_indicators(first_reply['message']):\n",
    "                validation['missing_elements'].append('proper_first_reply')\n",
    "                details.append(\"‚ö†Ô∏è First reply doesn't contain proper acknowledgment\")\n",
    "        \n",
    "        # Requirement: Untuk semua issue type harus ada FINAL reply\n",
    "        if not final_reply:\n",
    "            validation['missing_elements'].append('final_reply')\n",
    "            details.append(\"‚ùå FINAL reply missing\")\n",
    "        elif self._is_conversation_ender(final_reply['message']):\n",
    "            validation['missing_elements'].append('meaningful_final_reply')\n",
    "            details.append(\"‚ö†Ô∏è Final reply is just conversation ender\")\n",
    "        \n",
    "        # Requirement: First dan Final reply tidak boleh sama\n",
    "        if first_reply and final_reply and first_reply['timestamp'] == final_reply['timestamp']:\n",
    "            validation['missing_elements'].append('duplicate_replies')\n",
    "            details.append(\"‚ùå First and final reply are the same message\")\n",
    "        \n",
    "        # Check conversation completeness\n",
    "        answered_pairs = sum(1 for p in qa_pairs if p['is_answered'])\n",
    "        if answered_pairs == 0:\n",
    "            details.append(\"üö® No answered questions in conversation\")\n",
    "        elif answered_pairs == 1 and first_reply and final_reply:\n",
    "            details.append(\"‚ö†Ô∏è Only one answered question found\")\n",
    "        \n",
    "        # Calculate quality score\n",
    "        score = 0\n",
    "        if first_reply:\n",
    "            score += 2\n",
    "            if self._contains_first_reply_indicators(first_reply['message']):\n",
    "                score += 1\n",
    "        if final_reply:\n",
    "            score += 2\n",
    "            if self._contains_final_reply_indicators(final_reply['message']):\n",
    "                score += 2\n",
    "            elif self._is_meaningful_reply(final_reply['message']):\n",
    "                score += 1\n",
    "        \n",
    "        validation['quality_score'] = score\n",
    "        validation['quality_rating'] = self._get_quality_rating(score)\n",
    "        validation['validation_details'] = details\n",
    "        \n",
    "        # Build recommendation\n",
    "        if not validation['missing_elements'] and score >= 4:\n",
    "            validation['recommendation'] = '‚úÖ Replies meet requirements'\n",
    "        else:\n",
    "            issues = \", \".join(validation['missing_elements'])\n",
    "            validation['recommendation'] = f'‚ö†Ô∏è Needs improvement: {issues}'\n",
    "        \n",
    "        return validation\n",
    "    \n",
    "    def _calculate_lead_times(self, qa_pairs, first_reply, final_reply, issue_type):\n",
    "        \"\"\"Hitung lead times - FIXED\"\"\"\n",
    "        lead_times = {}\n",
    "        \n",
    "        if not qa_pairs:\n",
    "            return lead_times\n",
    "        \n",
    "        main_question_time = qa_pairs[0]['question_time']\n",
    "        \n",
    "        # First reply lead time\n",
    "        if first_reply and first_reply['timestamp']:\n",
    "            lead_times['first_reply_lead_time_seconds'] = (\n",
    "                first_reply['timestamp'] - main_question_time\n",
    "            ).total_seconds()\n",
    "            lead_times['first_reply_lead_time_minutes'] = round(\n",
    "                lead_times['first_reply_lead_time_seconds'] / 60, 2\n",
    "            )\n",
    "            lead_times['first_reply_lead_time_hhmmss'] = self._seconds_to_hhmmss(\n",
    "                lead_times['first_reply_lead_time_seconds']\n",
    "            )\n",
    "        \n",
    "        # Final reply lead time\n",
    "        if final_reply and final_reply['timestamp']:\n",
    "            lead_times['final_reply_lead_time_seconds'] = (\n",
    "                final_reply['timestamp'] - main_question_time\n",
    "            ).total_seconds()\n",
    "            lead_times['final_reply_lead_time_minutes'] = round(\n",
    "                lead_times['final_reply_lead_time_seconds'] / 60, 2\n",
    "            )\n",
    "            lead_times['final_reply_lead_time_hhmmss'] = self._seconds_to_hhmmss(\n",
    "                lead_times['final_reply_lead_time_seconds']\n",
    "            )\n",
    "        \n",
    "        return lead_times\n",
    "    \n",
    "    def _check_thresholds(self, lead_times, issue_type):\n",
    "        \"\"\"Check threshold violations - FIXED\"\"\"\n",
    "        checks = {}\n",
    "        \n",
    "        if issue_type == 'normal' and 'final_reply_lead_time_minutes' in lead_times:\n",
    "            lt = lead_times['final_reply_lead_time_minutes']\n",
    "            checks['normal_threshold_exceeded'] = lt > self.time_thresholds['normal_final']\n",
    "            checks['normal_threshold_minutes'] = self.time_thresholds['normal_final']\n",
    "            checks['actual_minutes'] = lt\n",
    "        \n",
    "        elif issue_type in ['serious', 'complaint']:\n",
    "            if 'first_reply_lead_time_minutes' in lead_times:\n",
    "                lt_first = lead_times['first_reply_lead_time_minutes']\n",
    "                threshold = self.time_thresholds['serious_first'] if issue_type == 'serious' else self.time_thresholds['complaint_first']\n",
    "                checks['first_threshold_exceeded'] = lt_first > threshold\n",
    "                checks['first_threshold_minutes'] = threshold\n",
    "                checks['first_actual_minutes'] = lt_first\n",
    "            \n",
    "            if 'final_reply_lead_time_minutes' in lead_times:\n",
    "                lt_final = lead_times['final_reply_lead_time_minutes']\n",
    "                threshold = self.time_thresholds['serious_final'] if issue_type == 'serious' else self.time_thresholds['complaint_final']\n",
    "                checks['final_threshold_exceeded'] = lt_final > threshold\n",
    "                checks['final_threshold_minutes'] = threshold\n",
    "                checks['final_actual_minutes'] = lt_final\n",
    "        \n",
    "        return checks\n",
    "    \n",
    "    def _analyze_performance(self, lead_times, issue_type):\n",
    "        \"\"\"Analyze performance - FIXED\"\"\"\n",
    "        performance = {\n",
    "            'issue_type': issue_type,\n",
    "            'performance_rating': 'unknown',\n",
    "            'response_efficiency': 'unknown',\n",
    "            'resolution_efficiency': 'unknown',\n",
    "            'performance_details': []\n",
    "        }\n",
    "        \n",
    "        details = []\n",
    "        \n",
    "        if issue_type == 'normal' and 'final_reply_lead_time_minutes' in lead_times:\n",
    "            lt = lead_times['final_reply_lead_time_minutes']\n",
    "            if lt <= 2:\n",
    "                performance.update({'performance_rating': 'excellent', 'response_efficiency': 'excellent'})\n",
    "                details.append(\"‚úÖ Excellent response time for normal issue\")\n",
    "            elif lt <= 5:\n",
    "                performance.update({'performance_rating': 'good', 'response_efficiency': 'good'})\n",
    "                details.append(\"‚úÖ Good response time for normal issue\")\n",
    "            elif lt <= 10:\n",
    "                performance.update({'performance_rating': 'fair', 'response_efficiency': 'fair'})\n",
    "                details.append(\"‚ö†Ô∏è Fair response time for normal issue\")\n",
    "            else:\n",
    "                performance.update({'performance_rating': 'poor', 'response_efficiency': 'poor'})\n",
    "                details.append(\"‚ùå Poor response time for normal issue\")\n",
    "        \n",
    "        elif issue_type in ['serious', 'complaint']:\n",
    "            # First response efficiency\n",
    "            if 'first_reply_lead_time_minutes' in lead_times:\n",
    "                lt_first = lead_times['first_reply_lead_time_minutes']\n",
    "                if lt_first <= 2:\n",
    "                    performance['response_efficiency'] = 'excellent'\n",
    "                    details.append(\"‚úÖ Excellent first response time\")\n",
    "                elif lt_first <= 5:\n",
    "                    performance['response_efficiency'] = 'good'\n",
    "                    details.append(\"‚úÖ Good first response time\")\n",
    "                elif lt_first <= 10:\n",
    "                    performance['response_efficiency'] = 'fair'\n",
    "                    details.append(\"‚ö†Ô∏è Fair first response time\")\n",
    "                else:\n",
    "                    performance['response_efficiency'] = 'poor'\n",
    "                    details.append(\"‚ùå Poor first response time\")\n",
    "            \n",
    "            # Final resolution efficiency\n",
    "            if 'final_reply_lead_time_minutes' in lead_times:\n",
    "                lt_final = lead_times['final_reply_lead_time_minutes']\n",
    "                max_threshold = self.time_thresholds['serious_final'] if issue_type == 'serious' else self.time_thresholds['complaint_final']\n",
    "                \n",
    "                if lt_final <= max_threshold * 0.3:\n",
    "                    performance['resolution_efficiency'] = 'excellent'\n",
    "                    details.append(\"‚úÖ Excellent resolution time\")\n",
    "                elif lt_final <= max_threshold * 0.6:\n",
    "                    performance['resolution_efficiency'] = 'good'\n",
    "                    details.append(\"‚úÖ Good resolution time\")\n",
    "                elif lt_final <= max_threshold:\n",
    "                    performance['resolution_efficiency'] = 'fair'\n",
    "                    details.append(\"‚ö†Ô∏è Fair resolution time\")\n",
    "                else:\n",
    "                    performance['resolution_efficiency'] = 'poor'\n",
    "                    details.append(\"‚ùå Poor resolution time\")\n",
    "            \n",
    "            # Overall rating\n",
    "            if (performance['response_efficiency'] in ['excellent', 'good'] and \n",
    "                performance['resolution_efficiency'] in ['excellent', 'good']):\n",
    "                performance['performance_rating'] = 'excellent'\n",
    "            elif (performance['response_efficiency'] in ['excellent', 'good', 'fair'] and \n",
    "                  performance['resolution_efficiency'] in ['excellent', 'good', 'fair']):\n",
    "                performance['performance_rating'] = 'good'\n",
    "            else:\n",
    "                performance['performance_rating'] = 'poor'\n",
    "        \n",
    "        performance['performance_details'] = details\n",
    "        return performance\n",
    "    \n",
    "    def _assess_quality(self, first_reply, final_reply, issue_type):\n",
    "        \"\"\"Assess reply quality - FIXED\"\"\"\n",
    "        quality = {\n",
    "            'first_reply_quality': 'unknown',\n",
    "            'final_reply_quality': 'unknown',\n",
    "            'overall_quality': 'unknown',\n",
    "            'quality_details': []\n",
    "        }\n",
    "        \n",
    "        details = []\n",
    "        \n",
    "        if first_reply:\n",
    "            if self._contains_first_reply_indicators(first_reply['message']):\n",
    "                quality['first_reply_quality'] = 'excellent'\n",
    "                details.append(\"‚úÖ First reply shows proper acknowledgment\")\n",
    "            elif self._is_meaningful_reply(first_reply['message']):\n",
    "                quality['first_reply_quality'] = 'good'\n",
    "                details.append(\"‚úÖ First reply is meaningful\")\n",
    "            else:\n",
    "                quality['first_reply_quality'] = 'poor'\n",
    "                details.append(\"‚ùå First reply is not meaningful\")\n",
    "        \n",
    "        if final_reply:\n",
    "            if self._contains_final_reply_indicators(final_reply['message']):\n",
    "                quality['final_reply_quality'] = 'excellent'\n",
    "                details.append(\"‚úÖ Final reply provides solution/information\")\n",
    "            elif self._is_meaningful_reply(final_reply['message']):\n",
    "                quality['final_reply_quality'] = 'good'\n",
    "                details.append(\"‚úÖ Final reply is meaningful\")\n",
    "            else:\n",
    "                quality['final_reply_quality'] = 'poor'\n",
    "                details.append(\"‚ùå Final reply is not meaningful\")\n",
    "        \n",
    "        # Overall quality\n",
    "        if (quality['first_reply_quality'] in ['excellent', 'good'] and \n",
    "            quality['final_reply_quality'] in ['excellent', 'good']):\n",
    "            quality['overall_quality'] = 'excellent'\n",
    "        elif (quality['first_reply_quality'] in ['excellent', 'good', 'fair'] and \n",
    "              quality['final_reply_quality'] in ['excellent', 'good', 'fair']):\n",
    "            quality['overall_quality'] = 'good'\n",
    "        else:\n",
    "            quality['overall_quality'] = 'poor'\n",
    "        \n",
    "        quality['quality_details'] = details\n",
    "        return quality\n",
    "    \n",
    "    def _create_reply_object(self, pair, reply_type):\n",
    "        \"\"\"Create reply object\"\"\"\n",
    "        return {\n",
    "            'message': pair['answer'],\n",
    "            'timestamp': pair['answer_time'],\n",
    "            'role': pair['answer_role'],\n",
    "            'reply_type': reply_type,\n",
    "            'lead_time_seconds': pair.get('lead_time_seconds'),\n",
    "            'lead_time_minutes': pair.get('lead_time_minutes'),\n",
    "            'lead_time_hhmmss': pair.get('lead_time_hhmmss'),\n",
    "            'question': pair['question'],\n",
    "            'question_time': pair['question_time']\n",
    "        }\n",
    "    \n",
    "    def _create_empty_analysis(self, issue_type, reason):\n",
    "        \"\"\"Create empty analysis result\"\"\"\n",
    "        return {\n",
    "            'issue_type': issue_type,\n",
    "            'lead_times': {},\n",
    "            'reply_validation': {\n",
    "                'first_reply_found': False,\n",
    "                'final_reply_found': False,\n",
    "                'recommendation': reason,\n",
    "                'missing_elements': ['first_reply', 'final_reply'],\n",
    "                'quality_score': 0,\n",
    "                'quality_rating': 'poor',\n",
    "                'validation_details': [reason]\n",
    "            },\n",
    "            'performance_analysis': {\n",
    "                'issue_type': issue_type,\n",
    "                'performance_rating': 'unknown',\n",
    "                'response_efficiency': 'unknown',\n",
    "                'resolution_efficiency': 'unknown',\n",
    "                'performance_details': [reason]\n",
    "            },\n",
    "            'threshold_checks': {},\n",
    "            'quality_assessment': {\n",
    "                'first_reply_quality': 'unknown',\n",
    "                'final_reply_quality': 'unknown',\n",
    "                'overall_quality': 'poor',\n",
    "                'quality_details': [reason]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _get_quality_rating(self, score):\n",
    "        \"\"\"Convert quality score to rating\"\"\"\n",
    "        if score >= 5:\n",
    "            return 'excellent'\n",
    "        elif score >= 3:\n",
    "            return 'good'\n",
    "        elif score >= 1:\n",
    "            return 'fair'\n",
    "        else:\n",
    "            return 'poor'\n",
    "    \n",
    "    def _seconds_to_hhmmss(self, seconds):\n",
    "        \"\"\"Convert seconds to HH:MM:SS format\"\"\"\n",
    "        try:\n",
    "            hours = int(seconds // 3600)\n",
    "            minutes = int((seconds % 3600) // 60)\n",
    "            seconds = int(seconds % 60)\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        except:\n",
    "            return \"00:00:00\"\n",
    "\n",
    "# Initialize FIXED Reply Analyzer\n",
    "reply_analyzer = ReplyAnalyzer()\n",
    "\n",
    "print(\"‚úÖ COMPLETELY FIXED Reply Analyzer Ready!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b92e50",
   "metadata": {},
   "source": [
    "Complete Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f576be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8 - CompleteAnalysisPipeline (FULL FIX)\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "class CompleteAnalysisPipeline:\n",
    "    def __init__(self):\n",
    "        self.preprocessor = DataPreprocessor()\n",
    "        self.parser = ConversationParser()\n",
    "        self.issue_detector = MainIssueDetector()\n",
    "        self.classifier = HybridClassifier()\n",
    "        self.reply_analyzer = ReplyAnalyzer()\n",
    "        self.results = []\n",
    "        self.analysis_stats = {}\n",
    "        \n",
    "        print(\"üöÄ Complete Analysis Pipeline Initialized\")\n",
    "        print(\"   ‚úì Data Preprocessor\")\n",
    "        print(\"   ‚úì Conversation Parser\") \n",
    "        print(\"   ‚úì Main Issue Detector\")\n",
    "        print(\"   ‚úì Hybrid Classifier\")\n",
    "        print(\"   ‚úì Reply Analyzer\")\n",
    "    \n",
    "    def analyze_single_ticket(self, ticket_df, ticket_id):\n",
    "        \"\"\"Analisis lengkap untuk single ticket - SIMPAN SEMUA DATA\"\"\"\n",
    "        print(f\"üéØ Analyzing Ticket: {ticket_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Parse Q-A pairs\n",
    "            qa_pairs = self.parser.parse_conversation(ticket_df)\n",
    "            \n",
    "            if not qa_pairs:\n",
    "                return self._create_ticket_result(ticket_id, \"failed\", \"No Q-A pairs detected\", {})\n",
    "            \n",
    "            answered_count = sum(1 for pair in qa_pairs if pair['is_answered'])\n",
    "            print(f\"   ‚úì Found {len(qa_pairs)} Q-A pairs ({answered_count} answered)\")\n",
    "            \n",
    "            # Step 2: Detect main issue\n",
    "            main_issue = self.issue_detector.detect_main_issue(qa_pairs)\n",
    "            \n",
    "            if not main_issue:\n",
    "                return self._create_ticket_result(ticket_id, \"failed\", \"No main issue detected\", {})\n",
    "            \n",
    "            print(f\"   ‚úì Main issue: {main_issue['issue_type']} (conf: {main_issue['confidence_score']:.2f})\")\n",
    "            \n",
    "            # Step 3: Classify issue type (double-check dengan ML)\n",
    "            ml_prediction, ml_confidence = self.classifier.predict(main_issue['question'])\n",
    "            final_issue_type = self._resolve_issue_type(main_issue['issue_type'], ml_prediction, ml_confidence)\n",
    "            \n",
    "            print(f\"   ‚úì Final classification: {final_issue_type} (ML conf: {ml_confidence:.2f})\")\n",
    "            \n",
    "            # Step 4: Analyze replies and lead times\n",
    "            first_reply, final_reply, reply_analysis = self.reply_analyzer.analyze_replies(\n",
    "                qa_pairs, final_issue_type\n",
    "            )\n",
    "            \n",
    "            # Step 5: Compile COMPREHENSIVE results dengan SEMUA DATA\n",
    "            result = {\n",
    "                'ticket_id': ticket_id,\n",
    "                'status': 'success',\n",
    "                'analysis_timestamp': datetime.now(),\n",
    "                \n",
    "                # Conversation info\n",
    "                'total_messages': len(ticket_df),\n",
    "                'total_qa_pairs': len(qa_pairs),\n",
    "                'answered_pairs': answered_count,\n",
    "                'conversation_duration_minutes': reply_analysis.get('lead_times', {}).get('conversation_duration_minutes', 0),\n",
    "                \n",
    "                # Main issue analysis - LENGKAP\n",
    "                'main_question': main_issue['question'],\n",
    "                'main_question_time': main_issue['question_time'],\n",
    "                'detected_issue_type': main_issue['issue_type'],\n",
    "                'detection_confidence': main_issue['confidence_score'],\n",
    "                'final_issue_type': final_issue_type,\n",
    "                'ml_prediction': ml_prediction,\n",
    "                'ml_confidence': ml_confidence,\n",
    "                'main_issue_reason': main_issue['selected_reason'],\n",
    "                \n",
    "                # Reply analysis - LENGKAP\n",
    "                'first_reply_found': reply_analysis['reply_validation']['first_reply_found'],\n",
    "                'final_reply_found': reply_analysis['reply_validation']['final_reply_found'],\n",
    "                'first_reply_message': first_reply['message'] if first_reply else None,\n",
    "                'first_reply_time': first_reply['timestamp'] if first_reply else None,\n",
    "                'final_reply_message': final_reply['message'] if final_reply else None,\n",
    "                'final_reply_time': final_reply['timestamp'] if final_reply else None,\n",
    "                \n",
    "                # Lead times - LENGKAP\n",
    "                'first_reply_lead_time_minutes': reply_analysis['lead_times'].get('first_reply_lead_time_minutes'),\n",
    "                'final_reply_lead_time_minutes': reply_analysis['lead_times'].get('final_reply_lead_time_minutes'),\n",
    "                'first_reply_lead_time_hhmmss': reply_analysis['lead_times'].get('first_reply_lead_time_hhmmss'),\n",
    "                'final_reply_lead_time_hhmmss': reply_analysis['lead_times'].get('final_reply_lead_time_hhmmss'),\n",
    "                \n",
    "                # Performance metrics\n",
    "                'performance_rating': reply_analysis['performance_analysis']['performance_rating'],\n",
    "                'response_efficiency': reply_analysis['performance_analysis'].get('response_efficiency', 'unknown'),\n",
    "                'resolution_efficiency': reply_analysis['performance_analysis'].get('resolution_efficiency', 'unknown'),\n",
    "                'quality_rating': reply_analysis['reply_validation']['quality_rating'],\n",
    "                'quality_score': reply_analysis['reply_validation']['quality_score'],\n",
    "                \n",
    "                # Threshold checks\n",
    "                'threshold_violations': self._extract_threshold_violations(reply_analysis['threshold_checks']),\n",
    "                \n",
    "                # Recommendations\n",
    "                'recommendation': reply_analysis['reply_validation']['recommendation'],\n",
    "                'missing_elements': reply_analysis['reply_validation']['missing_elements'],\n",
    "                \n",
    "                # ‚úÖ‚úÖ‚úÖ RAW DATA LENGKAP UNTUK EXPORT ‚úÖ‚úÖ‚úÖ\n",
    "                '_raw_qa_pairs': qa_pairs,                    # SEMUA Q-A PAIRS\n",
    "                '_raw_main_issue': main_issue,                # DETAIL MAIN ISSUE\n",
    "                '_raw_reply_analysis': reply_analysis         # DETAIL REPLY ANALYSIS\n",
    "            }\n",
    "            \n",
    "            print(f\"   ‚úÖ Analysis completed - Performance: {result['performance_rating'].upper()}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            print(f\"   ‚ùå Analysis failed: {error_msg}\")\n",
    "            return self._create_ticket_result(ticket_id, \"failed\", error_msg, {})\n",
    "    \n",
    "    def _resolve_issue_type(self, detected_type, ml_prediction, ml_confidence):\n",
    "        \"\"\"Resolve final issue type antara rule-based dan ML\"\"\"\n",
    "        if ml_confidence > 0.7:  # High confidence ML\n",
    "            return ml_prediction\n",
    "        elif ml_confidence > 0.5 and ml_prediction == detected_type:  # Consistent\n",
    "            return ml_prediction\n",
    "        else:  # Trust rule-based detection\n",
    "            return detected_type\n",
    "    \n",
    "    def _extract_threshold_violations(self, threshold_checks):\n",
    "        \"\"\"Extract threshold violations dari analysis\"\"\"\n",
    "        violations = []\n",
    "        for key, value in threshold_checks.items():\n",
    "            if 'exceeded' in key and value:\n",
    "                violations.append(key)\n",
    "        return violations\n",
    "    \n",
    "    def _create_ticket_result(self, ticket_id, status, reason, extra_data):\n",
    "        \"\"\"Create standardized result object\"\"\"\n",
    "        result = {\n",
    "            'ticket_id': ticket_id,\n",
    "            'status': status,\n",
    "            'failure_reason': reason if status == 'failed' else None,\n",
    "            'analysis_timestamp': datetime.now()\n",
    "        }\n",
    "        result.update(extra_data)\n",
    "        return result\n",
    "    \n",
    "    def analyze_all_tickets(self, df, sample_size=None, max_tickets=None):\n",
    "        \"\"\"Analisis semua tickets dengan comprehensive reporting\"\"\"\n",
    "        print(\"üöÄ STARTING COMPLETE ANALYSIS PIPELINE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        ticket_ids = df['Ticket Number'].unique()\n",
    "        \n",
    "        if sample_size:\n",
    "            ticket_ids = ticket_ids[:sample_size]\n",
    "            print(f\"üîç Analyzing {sample_size} sample tickets...\")\n",
    "        elif max_tickets:\n",
    "            ticket_ids = ticket_ids[:max_tickets]\n",
    "            print(f\"üîç Analyzing {max_tickets} tickets (max limit)...\")\n",
    "        else:\n",
    "            print(f\"üîç Analyzing {len(ticket_ids)} tickets...\")\n",
    "        \n",
    "        self.results = []\n",
    "        successful_analyses = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, ticket_id in enumerate(ticket_ids):\n",
    "            ticket_df = df[df['Ticket Number'] == ticket_id]\n",
    "            \n",
    "            result = self.analyze_single_ticket(ticket_df, ticket_id)\n",
    "            self.results.append(result)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                successful_analyses += 1\n",
    "            \n",
    "            # Progress reporting\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(ticket_ids):\n",
    "                progress = (i + 1) / len(ticket_ids) * 100\n",
    "                print(f\"   üìä Progress: {i + 1}/{len(ticket_ids)} ({progress:.1f}%) - {successful_analyses} successful\")\n",
    "        \n",
    "        # Calculate comprehensive statistics\n",
    "        analysis_time = time.time() - start_time\n",
    "        self.analysis_stats = self._calculate_comprehensive_stats(analysis_time)\n",
    "        \n",
    "        print(f\"\\nüéâ ANALYSIS PIPELINE COMPLETED!\")\n",
    "        print(\"=\" * 60)\n",
    "        self._print_summary_report()\n",
    "        \n",
    "        return self.results, self.analysis_stats\n",
    "    \n",
    "    def _calculate_comprehensive_stats(self, analysis_time):\n",
    "        \"\"\"Hitung comprehensive statistics dari results\"\"\"\n",
    "        successful = [r for r in self.results if r['status'] == 'success']\n",
    "        failed = [r for r in self.results if r['status'] == 'failed']\n",
    "        \n",
    "        if not successful:\n",
    "            return {\n",
    "                'total_tickets': len(self.results),\n",
    "                'successful_analysis': 0,\n",
    "                'failed_analysis': len(failed),\n",
    "                'success_rate': 0,\n",
    "                'analysis_duration_seconds': analysis_time\n",
    "            }\n",
    "        \n",
    "        # Basic stats\n",
    "        stats = {\n",
    "            'total_tickets': len(self.results),\n",
    "            'successful_analysis': len(successful),\n",
    "            'failed_analysis': len(failed),\n",
    "            'success_rate': len(successful) / len(self.results),\n",
    "            'analysis_duration_seconds': analysis_time,\n",
    "            'avg_analysis_time_per_ticket': analysis_time / len(self.results)\n",
    "        }\n",
    "        \n",
    "        # Issue type distribution\n",
    "        issue_types = [r['final_issue_type'] for r in successful]\n",
    "        stats['issue_type_distribution'] = dict(Counter(issue_types))\n",
    "        \n",
    "        # Performance metrics\n",
    "        performance_ratings = [r['performance_rating'] for r in successful]\n",
    "        stats['performance_distribution'] = dict(Counter(performance_ratings))\n",
    "        \n",
    "        # Lead time statistics\n",
    "        lead_times = [r['final_reply_lead_time_minutes'] for r in successful if r['final_reply_lead_time_minutes'] is not None]\n",
    "        if lead_times:\n",
    "            stats['lead_time_stats'] = {\n",
    "                'avg_lead_time_minutes': np.mean(lead_times),\n",
    "                'median_lead_time_minutes': np.median(lead_times),\n",
    "                'min_lead_time_minutes': np.min(lead_times),\n",
    "                'max_lead_time_minutes': np.max(lead_times),\n",
    "                'std_lead_time_minutes': np.std(lead_times)\n",
    "            }\n",
    "        \n",
    "        # Quality metrics\n",
    "        quality_scores = [r['quality_score'] for r in successful]\n",
    "        stats['quality_stats'] = {\n",
    "            'avg_quality_score': np.mean(quality_scores),\n",
    "            'avg_quality_rating': Counter([r['quality_rating'] for r in successful]).most_common(1)[0][0]\n",
    "        }\n",
    "        \n",
    "        # Threshold violations\n",
    "        all_violations = []\n",
    "        for r in successful:\n",
    "            all_violations.extend(r.get('threshold_violations', []))\n",
    "        stats['threshold_violations'] = dict(Counter(all_violations))\n",
    "        \n",
    "        # Reply effectiveness\n",
    "        stats['reply_effectiveness'] = {\n",
    "            'first_reply_found_rate': sum(1 for r in successful if r['first_reply_found']) / len(successful),\n",
    "            'final_reply_found_rate': sum(1 for r in successful if r['final_reply_found']) / len(successful),\n",
    "            'both_replies_found_rate': sum(1 for r in successful if r['first_reply_found'] and r['final_reply_found']) / len(successful)\n",
    "        }\n",
    "\n",
    "        # Q-A Pairs Statistics\n",
    "        total_qa_pairs = sum(r['total_qa_pairs'] for r in successful)\n",
    "        total_answered_pairs = sum(r['answered_pairs'] for r in successful)\n",
    "        stats['qa_pairs_stats'] = {\n",
    "            'total_qa_pairs': total_qa_pairs,\n",
    "            'total_answered_pairs': total_answered_pairs,\n",
    "            'answer_rate': total_answered_pairs / total_qa_pairs if total_qa_pairs > 0 else 0,\n",
    "            'avg_qa_pairs_per_ticket': total_qa_pairs / len(successful) if successful else 0\n",
    "        }\n",
    "\n",
    "        # Raw Data Availability\n",
    "        raw_data_available = {\n",
    "            'qa_pairs_available': sum(1 for r in successful if '_raw_qa_pairs' in r),\n",
    "            'main_issue_available': sum(1 for r in successful if '_raw_main_issue' in r),\n",
    "            'reply_analysis_available': sum(1 for r in successful if '_raw_reply_analysis' in r)\n",
    "        }\n",
    "        stats['raw_data_availability'] = raw_data_available\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _print_summary_report(self):\n",
    "        \"\"\"Print comprehensive summary report\"\"\"\n",
    "        stats = self.analysis_stats\n",
    "        \n",
    "        print(f\"üìä COMPREHENSIVE ANALYSIS REPORT\")\n",
    "        print(f\"   ‚Ä¢ Total Tickets: {stats['total_tickets']}\")\n",
    "        print(f\"   ‚Ä¢ Successful Analysis: {stats['successful_analysis']} ({stats['success_rate']*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Analysis Duration: {stats['analysis_duration_seconds']:.1f}s\")\n",
    "        print(f\"   ‚Ä¢ Avg Time per Ticket: {stats['avg_analysis_time_per_ticket']:.2f}s\")\n",
    "        \n",
    "        if 'issue_type_distribution' in stats:\n",
    "            print(f\"\\nüéØ ISSUE TYPE DISTRIBUTION:\")\n",
    "            for issue_type, count in stats['issue_type_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                print(f\"   ‚Ä¢ {issue_type.title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if 'lead_time_stats' in stats:\n",
    "            lt_stats = stats['lead_time_stats']\n",
    "            print(f\"\\n‚è±Ô∏è LEAD TIME STATISTICS:\")\n",
    "            print(f\"   ‚Ä¢ Average: {lt_stats['avg_lead_time_minutes']:.2f} min\")\n",
    "            print(f\"   ‚Ä¢ Median: {lt_stats['median_lead_time_minutes']:.2f} min\") \n",
    "            print(f\"   ‚Ä¢ Range: {lt_stats['min_lead_time_minutes']:.2f} - {lt_stats['max_lead_time_minutes']:.2f} min\")\n",
    "        \n",
    "        if 'performance_distribution' in stats:\n",
    "            print(f\"\\nüìà PERFORMANCE DISTRIBUTION:\")\n",
    "            for rating, count in stats['performance_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                print(f\"   ‚Ä¢ {rating.upper()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if 'threshold_violations' in stats:\n",
    "            print(f\"\\nüö® THRESHOLD VIOLATIONS:\")\n",
    "            for violation, count in stats['threshold_violations'].items():\n",
    "                print(f\"   ‚Ä¢ {violation}: {count}\")\n",
    "        \n",
    "        if 'reply_effectiveness' in stats:\n",
    "            eff = stats['reply_effectiveness']\n",
    "            print(f\"\\nüí¨ REPLY EFFECTIVENESS:\")\n",
    "            print(f\"   ‚Ä¢ First Reply Found: {eff['first_reply_found_rate']*100:.1f}%\")\n",
    "            print(f\"   ‚Ä¢ Final Reply Found: {eff['final_reply_found_rate']*100:.1f}%\")\n",
    "            print(f\"   ‚Ä¢ Both Replies Found: {eff['both_replies_found_rate']*100:.1f}%\")\n",
    "\n",
    "        if 'qa_pairs_stats' in stats:\n",
    "            qa_stats = stats['qa_pairs_stats']\n",
    "            print(f\"\\nüîó Q-A PAIRS STATISTICS:\")\n",
    "            print(f\"   ‚Ä¢ Total Q-A Pairs: {qa_stats['total_qa_pairs']}\")\n",
    "            print(f\"   ‚Ä¢ Answered Pairs: {qa_stats['total_answered_pairs']} ({qa_stats['answer_rate']*100:.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Avg Pairs per Ticket: {qa_stats['avg_qa_pairs_per_ticket']:.1f}\")\n",
    "\n",
    "        if 'raw_data_availability' in stats:\n",
    "            raw_stats = stats['raw_data_availability']\n",
    "            print(f\"\\nüìÅ RAW DATA AVAILABILITY:\")\n",
    "            print(f\"   ‚Ä¢ Q-A Pairs Data: {raw_stats['qa_pairs_available']}/{stats['successful_analysis']} tickets\")\n",
    "            print(f\"   ‚Ä¢ Main Issue Data: {raw_stats['main_issue_available']}/{stats['successful_analysis']} tickets\")\n",
    "            print(f\"   ‚Ä¢ Reply Analysis Data: {raw_stats['reply_analysis_available']}/{stats['successful_analysis']} tickets\")\n",
    "\n",
    "    def export_results(self, output_file=\"output/pipeline_results.xlsx\"):\n",
    "        \"\"\"Export results ke Excel file\"\"\"\n",
    "        try:\n",
    "            # Prepare data untuk export\n",
    "            export_data = []\n",
    "            \n",
    "            for result in self.results:\n",
    "                if result['status'] == 'success':\n",
    "                    row = {\n",
    "                        'ticket_id': result['ticket_id'],\n",
    "                        'issue_type': result['final_issue_type'],\n",
    "                        'main_question': result['main_question'],\n",
    "                        'performance_rating': result['performance_rating'],\n",
    "                        'quality_rating': result['quality_rating'],\n",
    "                        'quality_score': result['quality_score'],\n",
    "                        'final_reply_lead_time_minutes': result.get('final_reply_lead_time_minutes'),\n",
    "                        'first_reply_found': result['first_reply_found'],\n",
    "                        'final_reply_found': result['final_reply_found'],\n",
    "                        'threshold_violations': ', '.join(result['threshold_violations']) if result['threshold_violations'] else 'None',\n",
    "                        'recommendation': result['recommendation'],\n",
    "                        'detection_confidence': result['detection_confidence'],\n",
    "                        'ml_confidence': result['ml_confidence'],\n",
    "                        'total_messages': result['total_messages'],\n",
    "                        'total_qa_pairs': result['total_qa_pairs'],\n",
    "                        'answered_pairs': result['answered_pairs'],\n",
    "                        'first_reply_message': result.get('first_reply_message', '')[:100] + '...' if result.get('first_reply_message') else '',\n",
    "                        'final_reply_message': result.get('final_reply_message', '')[:100] + '...' if result.get('final_reply_message') else ''\n",
    "                    }\n",
    "                    export_data.append(row)\n",
    "                else:\n",
    "                    row = {\n",
    "                        'ticket_id': result['ticket_id'],\n",
    "                        'issue_type': 'FAILED',\n",
    "                        'main_question': result.get('failure_reason', 'Analysis failed'),\n",
    "                        'performance_rating': 'N/A',\n",
    "                        'quality_rating': 'N/A',\n",
    "                        'quality_score': 0,\n",
    "                        'final_reply_lead_time_minutes': None,\n",
    "                        'first_reply_found': False,\n",
    "                        'final_reply_found': False,\n",
    "                        'threshold_violations': 'N/A',\n",
    "                        'recommendation': 'Analysis failed',\n",
    "                        'detection_confidence': 0,\n",
    "                        'ml_confidence': 0,\n",
    "                        'total_messages': 0,\n",
    "                        'total_qa_pairs': 0,\n",
    "                        'answered_pairs': 0,\n",
    "                        'first_reply_message': '',\n",
    "                        'final_reply_message': ''\n",
    "                    }\n",
    "                    export_data.append(row)\n",
    "            \n",
    "            # Create DataFrame dan save\n",
    "            df_export = pd.DataFrame(export_data)\n",
    "            \n",
    "            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "                # Detailed results\n",
    "                df_export.to_excel(writer, sheet_name='Detailed_Results', index=False)\n",
    "                \n",
    "                # Summary statistics\n",
    "                summary_data = self._create_summary_sheet()\n",
    "                summary_df = pd.DataFrame(summary_data)\n",
    "                summary_df.to_excel(writer, sheet_name='Summary_Statistics', index=False)\n",
    "                \n",
    "                # Performance metrics\n",
    "                perf_data = self._create_performance_sheet()\n",
    "                perf_df = pd.DataFrame(perf_data)\n",
    "                perf_df.to_excel(writer, sheet_name='Performance_Metrics', index=False)\n",
    "            \n",
    "            print(f\"üíæ Results exported to: {output_file}\")\n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting results: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _create_summary_sheet(self):\n",
    "        \"\"\"Create summary sheet data\"\"\"\n",
    "        stats = self.analysis_stats\n",
    "        \n",
    "        summary_data = [\n",
    "            ['COMPLETE ANALYSIS PIPELINE - SUMMARY REPORT', '', ''],\n",
    "            ['Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S'), ''],\n",
    "            ['', '', ''],\n",
    "            ['OVERALL STATISTICS', '', ''],\n",
    "            ['Total Tickets Processed', stats['total_tickets'], ''],\n",
    "            ['Successful Analysis', stats['successful_analysis'], ''],\n",
    "            ['Failed Analysis', stats['failed_analysis'], ''],\n",
    "            ['Success Rate', f\"{stats['success_rate']*100:.1f}%\", ''],\n",
    "            ['Total Analysis Time', f\"{stats['analysis_duration_seconds']:.1f} seconds\", ''],\n",
    "            ['Average Time per Ticket', f\"{stats['avg_analysis_time_per_ticket']:.2f} seconds\", ''],\n",
    "            ['', '', ''],\n",
    "            ['ISSUE TYPE DISTRIBUTION', 'Count', 'Percentage']\n",
    "        ]\n",
    "        \n",
    "        if 'issue_type_distribution' in stats:\n",
    "            for issue_type, count in stats['issue_type_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([issue_type.title(), count, f\"{percentage:.1f}%\"])\n",
    "        \n",
    "        summary_data.extend([\n",
    "            ['', '', ''],\n",
    "            ['PERFORMANCE DISTRIBUTION', 'Count', 'Percentage']\n",
    "        ])\n",
    "        \n",
    "        if 'performance_distribution' in stats:\n",
    "            for rating, count in stats['performance_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([rating.upper(), count, f\"{percentage:.1f}%\"])\n",
    "        \n",
    "        return summary_data\n",
    "    \n",
    "    def _create_performance_sheet(self):\n",
    "        \"\"\"Create performance metrics sheet\"\"\"\n",
    "        stats = self.analysis_stats\n",
    "        \n",
    "        perf_data = [\n",
    "            ['PERFORMANCE METRICS', 'Value', ''],\n",
    "            ['Reply Effectiveness', '', ''],\n",
    "            ['First Reply Found Rate', f\"{stats.get('reply_effectiveness', {}).get('first_reply_found_rate', 0)*100:.1f}%\", ''],\n",
    "            ['Final Reply Found Rate', f\"{stats.get('reply_effectiveness', {}).get('final_reply_found_rate', 0)*100:.1f}%\", ''],\n",
    "            ['Both Replies Found Rate', f\"{stats.get('reply_effectiveness', {}).get('both_replies_found_rate', 0)*100:.1f}%\", ''],\n",
    "            ['', '', ''],\n",
    "            ['Lead Time Statistics', '', '']\n",
    "        ]\n",
    "        \n",
    "        if 'lead_time_stats' in stats:\n",
    "            lt = stats['lead_time_stats']\n",
    "            perf_data.extend([\n",
    "                ['Average Lead Time', f\"{lt['avg_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Median Lead Time', f\"{lt['median_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Minimum Lead Time', f\"{lt['min_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Maximum Lead Time', f\"{lt['max_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Standard Deviation', f\"{lt['std_lead_time_minutes']:.2f} minutes\", '']\n",
    "            ])\n",
    "        \n",
    "        perf_data.extend([\n",
    "            ['', '', ''],\n",
    "            ['Quality Metrics', '', ''],\n",
    "            ['Average Quality Score', f\"{stats.get('quality_stats', {}).get('avg_quality_score', 0):.2f}/6\", ''],\n",
    "            ['Most Common Quality Rating', stats.get('quality_stats', {}).get('avg_quality_rating', 'N/A').upper(), '']\n",
    "        ])\n",
    "        \n",
    "        return perf_data\n",
    "\n",
    "# Initialize Fixed Pipeline\n",
    "pipeline = CompleteAnalysisPipeline()\n",
    "\n",
    "print(\"‚úÖ FULLY FIXED Complete Analysis Pipeline Ready!\")\n",
    "print(\"   ‚úì All raw data preserved for export\")\n",
    "print(\"   ‚úì Enhanced statistics tracking\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd97a2f",
   "metadata": {},
   "source": [
    "Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training & Evaluation dengan Real Data (FIXED)\n",
    "class ModelTrainer:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.training_data = []\n",
    "        self.evaluation_results = {}\n",
    "        \n",
    "    def collect_training_data_from_analysis(self, results):\n",
    "        \"\"\"Collect training data dari analysis results\"\"\"\n",
    "        print(\"üìö Collecting training data from analysis results...\")\n",
    "        \n",
    "        training_samples = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                # Use the final classification sebagai ground truth\n",
    "                training_samples.append({\n",
    "                    'text': result['main_question'],\n",
    "                    'label': result['final_issue_type'],\n",
    "                    'ticket_id': result['ticket_id'],\n",
    "                    'confidence': result['detection_confidence'],\n",
    "                    'ml_confidence': result['ml_confidence']\n",
    "                })\n",
    "        \n",
    "        self.training_data = training_samples\n",
    "        print(f\"‚úÖ Collected {len(training_samples)} training samples\")\n",
    "        return training_samples\n",
    "    \n",
    "    def enhance_training_data(self):\n",
    "        \"\"\"Enhance training data dengan manual corrections dan additional samples\"\"\"\n",
    "        print(\"üîÑ Enhancing training data...\")\n",
    "        \n",
    "        # Additional curated samples berdasarkan domain knowledge\n",
    "        enhanced_samples = [\n",
    "            # Additional NORMAL samples\n",
    "            {\"text\": \"berapa harga mobil avanza terbaru\", \"label\": \"normal\"},\n",
    "            {\"text\": \"info promo cashback toyota\", \"label\": \"normal\"},\n",
    "            {\"text\": \"cara booking test drive fortuner\", \"label\": \"normal\"},\n",
    "            {\"text\": \"alamat dealer toyota terdekat\", \"label\": \"normal\"},\n",
    "            {\"text\": \"jam operasional bengkel\", \"label\": \"normal\"},\n",
    "            {\"text\": \"spesifikasi lengkap rush\", \"label\": \"normal\"},\n",
    "            {\"text\": \"syarat kredit mobil baru\", \"label\": \"normal\"},\n",
    "            {\"text\": \"beda innova zenix dan innova lama\", \"label\": \"normal\"},\n",
    "            \n",
    "            # Additional SERIOUS samples  \n",
    "            {\"text\": \"mobil tiba-tiba mati di jalan tol\", \"label\": \"serious\"},\n",
    "            {\"text\": \"mesin overheating terus menerus\", \"label\": \"serious\"},\n",
    "            {\"text\": \"rem tidak berfungsi dengan baik\", \"label\": \"serious\"},\n",
    "            {\"text\": \"aki soak tidak bisa starter\", \"label\": \"serious\"},\n",
    "            {\"text\": \"lampu dashboard berkedip semua\", \"label\": \"serious\"},\n",
    "            {\"text\": \"oli mesin bocor parah\", \"label\": \"serious\"},\n",
    "            {\"text\": \"ban pecah di jalan cepat\", \"label\": \"serious\"},\n",
    "            {\"text\": \"mobil terbakar sendiri\", \"label\": \"serious\"},\n",
    "            \n",
    "            # Additional COMPLAINT samples\n",
    "            {\"text\": \"sangat kecewa dengan pelayanan bengkel\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"komplain sparepart palsu yang dipasang\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"protes untuk biaya servis yang mahal\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"minta refund untuk produk cacat\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"kecewa dengan waiting time yang lama\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"komplain untuk janji tidak ditepati\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"pelayanan customer service sangat buruk\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"protes untuk penanganan yang lamban\", \"label\": \"complaint\"}\n",
    "        ]\n",
    "        \n",
    "        # Combine dengan collected data\n",
    "        if self.training_data:\n",
    "            current_texts = [sample['text'] for sample in self.training_data]\n",
    "            for sample in enhanced_samples:\n",
    "                if sample['text'] not in current_texts:\n",
    "                    self.training_data.append(sample)\n",
    "        else:\n",
    "            self.training_data = enhanced_samples\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced training data: {len(self.training_data)} total samples\")\n",
    "        \n",
    "        # Show distribution\n",
    "        labels = [sample['label'] for sample in self.training_data]\n",
    "        distribution = Counter(labels)\n",
    "        print(f\"üìä Training data distribution: {dict(distribution)}\")\n",
    "    \n",
    "    def train_and_evaluate_model(self, test_size=0.2):\n",
    "        \"\"\"Train dan evaluate model dengan real data\"\"\"\n",
    "        if not self.training_data:\n",
    "            print(\"‚ùå No training data available\")\n",
    "            return None\n",
    "        \n",
    "        print(\"ü§ñ Training model with enhanced real data...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        texts = [sample['text'] for sample in self.training_data]\n",
    "        labels = [sample['label'] for sample in self.training_data]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            texts, labels, \n",
    "            test_size=test_size, \n",
    "            random_state=config.RANDOM_STATE,\n",
    "            stratify=labels\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Dataset: {len(texts)} samples\")\n",
    "        print(f\"üìä Training: {len(X_train)} samples\")\n",
    "        print(f\"üìä Testing: {len(X_test)} samples\")\n",
    "        print(f\"üìä Class distribution: {Counter(labels)}\")\n",
    "        \n",
    "        # Train model\n",
    "        success = self.pipeline.classifier.train(X_train, y_train)\n",
    "        \n",
    "        if success:\n",
    "            # Evaluate model\n",
    "            accuracy = self.pipeline.classifier.evaluate_model(X_test, y_test)\n",
    "            \n",
    "            # Store evaluation results\n",
    "            self.evaluation_results = {\n",
    "                'accuracy': accuracy,\n",
    "                'training_samples': len(X_train),\n",
    "                'test_samples': len(X_test),\n",
    "                'class_distribution': dict(Counter(labels)),\n",
    "                'test_distribution': dict(Counter(y_test))\n",
    "            }\n",
    "            \n",
    "            # Cross-validation untuk lebih robust evaluation\n",
    "            cv_results = self._cross_validate(texts, labels)\n",
    "            self.evaluation_results.update(cv_results)\n",
    "            \n",
    "            self._print_evaluation_report()\n",
    "            \n",
    "            return accuracy\n",
    "        else:\n",
    "            print(\"‚ùå Model training failed\")\n",
    "            return None\n",
    "    \n",
    "    def _cross_validate(self, texts, labels, cv_folds=5):\n",
    "        \"\"\"Perform cross-validation untuk robust evaluation\"\"\"\n",
    "        print(\"üîç Performing cross-validation...\")\n",
    "        \n",
    "        try:\n",
    "            from sklearn.model_selection import cross_val_score\n",
    "            \n",
    "            # Create pipeline untuk cross-validation\n",
    "            from sklearn.pipeline import Pipeline\n",
    "            cv_pipeline = Pipeline([\n",
    "                ('tfidf', self.pipeline.classifier.vectorizer),\n",
    "                ('clf', self.pipeline.classifier.classifier)\n",
    "            ])\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv_scores = cross_val_score(\n",
    "                cv_pipeline, texts, labels, \n",
    "                cv=cv_folds, scoring='accuracy'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'cross_val_accuracy_mean': np.mean(cv_scores),\n",
    "                'cross_val_accuracy_std': np.std(cv_scores),\n",
    "                'cross_val_scores': cv_scores.tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Cross-validation failed: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def _print_evaluation_report(self):\n",
    "        \"\"\"Print comprehensive evaluation report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä COMPREHENSIVE MODEL EVALUATION REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        eval_results = self.evaluation_results\n",
    "        \n",
    "        print(f\"üéØ ACCURACY METRICS:\")\n",
    "        print(f\"   ‚Ä¢ Test Accuracy: {eval_results.get('accuracy', 0):.3f}\")\n",
    "        if 'cross_val_accuracy_mean' in eval_results:\n",
    "            print(f\"   ‚Ä¢ Cross-Val Accuracy: {eval_results['cross_val_accuracy_mean']:.3f} (¬±{eval_results['cross_val_accuracy_std']:.3f})\")\n",
    "        \n",
    "        print(f\"\\nüìä DATASET INFO:\")\n",
    "        print(f\"   ‚Ä¢ Total Samples: {eval_results.get('training_samples', 0) + eval_results.get('test_samples', 0)}\")\n",
    "        print(f\"   ‚Ä¢ Training Samples: {eval_results.get('training_samples', 0)}\")\n",
    "        print(f\"   ‚Ä¢ Test Samples: {eval_results.get('test_samples', 0)}\")\n",
    "        \n",
    "        if 'class_distribution' in eval_results:\n",
    "            print(f\"   ‚Ä¢ Class Distribution: {eval_results['class_distribution']}\")\n",
    "        \n",
    "        if 'cross_val_scores' in eval_results:\n",
    "            print(f\"\\nüîç CROSS-VALIDATION DETAILS:\")\n",
    "            for i, score in enumerate(eval_results['cross_val_scores']):\n",
    "                print(f\"   ‚Ä¢ Fold {i+1}: {score:.3f}\")\n",
    "        \n",
    "        # Model performance assessment\n",
    "        accuracy = eval_results.get('accuracy', 0)\n",
    "        if accuracy >= 0.9:\n",
    "            assessment = \"EXCELLENT üéØ\"\n",
    "        elif accuracy >= 0.8:\n",
    "            assessment = \"VERY GOOD ‚úÖ\"  \n",
    "        elif accuracy >= 0.7:\n",
    "            assessment = \"GOOD üëç\"\n",
    "        elif accuracy >= 0.6:\n",
    "            assessment = \"FAIR ‚ö†Ô∏è\"\n",
    "        else:\n",
    "            assessment = \"POOR ‚ùå\"\n",
    "        \n",
    "        print(f\"\\nüìà PERFORMANCE ASSESSMENT: {assessment}\")\n",
    "        \n",
    "        # Recommendations\n",
    "        print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "        if accuracy >= 0.85:\n",
    "            print(f\"   ‚Ä¢ Model ready for production use\")\n",
    "            print(f\"   ‚Ä¢ Continue monitoring performance\")\n",
    "        elif accuracy >= 0.7:\n",
    "            print(f\"   ‚Ä¢ Model acceptable for use\")\n",
    "            print(f\"   ‚Ä¢ Consider adding more training data\")\n",
    "        else:\n",
    "            print(f\"   ‚Ä¢ Model needs improvement\")\n",
    "            print(f\"   ‚Ä¢ Collect more labeled data\")\n",
    "            print(f\"   ‚Ä¢ Review feature engineering\")\n",
    "    \n",
    "    def analyze_model_confidence(self, results):\n",
    "        \"\"\"Analyze model confidence pada real predictions\"\"\"\n",
    "        print(\"\\nüîç Analyzing model confidence on real data...\")\n",
    "        \n",
    "        confident_predictions = 0\n",
    "        total_predictions = 0\n",
    "        confidence_scores = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                total_predictions += 1\n",
    "                ml_confidence = result.get('ml_confidence', 0)\n",
    "                confidence_scores.append(ml_confidence)\n",
    "                \n",
    "                if ml_confidence > 0.7:  # High confidence threshold\n",
    "                    confident_predictions += 1\n",
    "        \n",
    "        if total_predictions > 0:\n",
    "            avg_confidence = np.mean(confidence_scores)\n",
    "            high_confidence_rate = confident_predictions / total_predictions\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Total Predictions: {total_predictions}\")\n",
    "            print(f\"   ‚Ä¢ High Confidence Predictions: {confident_predictions} ({high_confidence_rate*100:.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Average Confidence: {avg_confidence:.3f}\")\n",
    "            print(f\"   ‚Ä¢ Confidence Range: {np.min(confidence_scores):.3f} - {np.max(confidence_scores):.3f}\")\n",
    "            \n",
    "            return {\n",
    "                'total_predictions': total_predictions,\n",
    "                'high_confidence_predictions': confident_predictions,\n",
    "                'high_confidence_rate': high_confidence_rate,\n",
    "                'avg_confidence': avg_confidence,\n",
    "                'confidence_scores': confidence_scores\n",
    "            }\n",
    "        \n",
    "        return {}\n",
    "\n",
    "    def save_model_report(self):\n",
    "        \"\"\"Save model evaluation report ke file\"\"\"\n",
    "        try:\n",
    "            report_path = \"output/model_evaluation_report.txt\"\n",
    "            \n",
    "            with open(report_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"ü§ñ CHAT ANALYSIS MODEL EVALUATION REPORT\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                \n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "                \n",
    "                # Accuracy metrics\n",
    "                f.write(\"ACCURACY METRICS:\\n\")\n",
    "                f.write(f\"- Test Accuracy: {self.evaluation_results.get('accuracy', 0):.3f}\\n\")\n",
    "                if 'cross_val_accuracy_mean' in self.evaluation_results:\n",
    "                    f.write(f\"- Cross-Val Accuracy: {self.evaluation_results['cross_val_accuracy_mean']:.3f} (¬±{self.evaluation_results['cross_val_accuracy_std']:.3f})\\n\")\n",
    "                \n",
    "                # Dataset info\n",
    "                f.write(f\"\\nDATASET INFO:\\n\")\n",
    "                f.write(f\"- Total Samples: {len(self.training_data)}\\n\")\n",
    "                f.write(f\"- Training Samples: {self.evaluation_results.get('training_samples', 0)}\\n\")\n",
    "                f.write(f\"- Test Samples: {self.evaluation_results.get('test_samples', 0)}\\n\")\n",
    "                f.write(f\"- Class Distribution: {self.evaluation_results.get('class_distribution', {})}\\n\")\n",
    "                \n",
    "                # Model info\n",
    "                f.write(f\"\\nMODEL INFO:\\n\")\n",
    "                f.write(f\"- Classifier: Logistic Regression\\n\")\n",
    "                f.write(f\"- Vectorizer: TF-IDF\\n\")\n",
    "                f.write(f\"- Features: {self.pipeline.classifier.vectorizer.max_features}\\n\")\n",
    "                \n",
    "                # Recommendations\n",
    "                accuracy = self.evaluation_results.get('accuracy', 0)\n",
    "                f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
    "                if accuracy >= 0.85:\n",
    "                    f.write(\"- ‚úÖ Model ready for production use\\n\")\n",
    "                elif accuracy >= 0.7:\n",
    "                    f.write(\"- ‚ö†Ô∏è Model acceptable, consider more training data\\n\")\n",
    "                else:\n",
    "                    f.write(\"- ‚ùå Model needs improvement\\n\")\n",
    "            \n",
    "            print(f\"üíæ Model evaluation report saved: {report_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving model report: {e}\")\n",
    "\n",
    "# Initialize Model Trainer\n",
    "model_trainer = ModelTrainer(pipeline)\n",
    "\n",
    "print(\"‚úÖ Model Trainer Ready!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test dengan sample data terlebih dahulu\n",
    "if raw_df is not None:\n",
    "    print(\"üß™ TESTING MODEL TRAINING WITH SAMPLE DATA...\")\n",
    "    \n",
    "    # Analyze sample tickets untuk collect training data\n",
    "    sample_tickets = raw_df['Ticket Number'].unique()[:10]  # 10 tickets sample\n",
    "    sample_results = []\n",
    "    \n",
    "    for ticket_id in sample_tickets:\n",
    "        ticket_df = raw_df[raw_df['Ticket Number'] == ticket_id]\n",
    "        result = pipeline.analyze_single_ticket(ticket_df, ticket_id)\n",
    "        sample_results.append(result)\n",
    "    \n",
    "    # Collect training data dari results\n",
    "    training_data = model_trainer.collect_training_data_from_analysis(sample_results)\n",
    "    \n",
    "    if training_data:\n",
    "        # Enhance training data\n",
    "        model_trainer.enhance_training_data()\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        accuracy = model_trainer.train_and_evaluate_model(test_size=0.3)\n",
    "        \n",
    "        if accuracy:\n",
    "            # Analyze confidence on real predictions\n",
    "            confidence_analysis = model_trainer.analyze_model_confidence(sample_results)\n",
    "            \n",
    "            # Save model report\n",
    "            model_trainer.save_model_report()\n",
    "            \n",
    "            print(f\"\\nüéØ MODEL TRAINING COMPLETED!\")\n",
    "            print(f\"   Final Accuracy: {accuracy:.3f}\")\n",
    "        else:\n",
    "            print(\"‚ùå Model training failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No training data collected\")\n",
    "\n",
    "def full_scale_training():\n",
    "    \"\"\"Full scale training dengan seluruh dataset\"\"\"\n",
    "    print(\"\\nüöÄ STARTING FULL-SCALE MODEL TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if raw_df is None:\n",
    "        print(\"‚ùå No data available for training\")\n",
    "        return\n",
    "    \n",
    "    # Analyze semua tickets untuk collect comprehensive training data\n",
    "    print(\"üìä Analyzing all tickets for training data collection...\")\n",
    "    all_results, stats = pipeline.analyze_all_tickets(raw_df, max_tickets=50)  # Limit untuk testing\n",
    "    \n",
    "    if all_results:\n",
    "        # Train model dengan comprehensive data\n",
    "        training_data = model_trainer.collect_training_data_from_analysis(all_results)\n",
    "        model_trainer.enhance_training_data()\n",
    "        accuracy = model_trainer.train_and_evaluate_model(test_size=0.2)\n",
    "        \n",
    "        if accuracy:\n",
    "            # Save comprehensive report\n",
    "            model_trainer.save_model_report()\n",
    "            \n",
    "            print(f\"\\nüéâ FULL-SCALE TRAINING COMPLETED!\")\n",
    "            print(f\"   Model Accuracy: {accuracy:.3f}\")\n",
    "            print(f\"   Training Samples: {len(model_trainer.training_data)}\")\n",
    "            print(f\"   Model ready for production use! üöÄ\")\n",
    "        else:\n",
    "            print(\"‚ùå Full-scale training failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No results for training\")\n",
    "\n",
    "# Option untuk run full-scale training\n",
    "print(f\"\\nüí° Untuk full-scale training, run: full_scale_training()\")\n",
    "print(f\"üí° Model sudah siap untuk digunakan dalam production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996e818",
   "metadata": {},
   "source": [
    "Results Export & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe944166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Export & Visualization\n",
    "class ResultsExporter:\n",
    "    def __init__(self):\n",
    "        self.output_dir = \"output/\"\n",
    "        self.reports_dir = f\"{self.output_dir}reports/\"\n",
    "        self.visualizations_dir = f\"{self.output_dir}visualizations/\"\n",
    "        \n",
    "        Path(self.output_dir).mkdir(exist_ok=True)\n",
    "        Path(self.reports_dir).mkdir(exist_ok=True)\n",
    "        Path(self.visualizations_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        print(\"‚úÖ Enhanced Results Exporter Initialized\")\n",
    "    \n",
    "    def export_comprehensive_results(self, results, stats, filename=\"comprehensive_analysis_results.xlsx\"):\n",
    "        \"\"\"Export COMPLETE results dengan semua data parse\"\"\"\n",
    "        output_path = f\"{self.output_dir}{filename}\"\n",
    "        \n",
    "        print(f\"üíæ Exporting COMPREHENSIVE results to {output_path}...\")\n",
    "        \n",
    "        try:\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                # Sheet 1: Detailed Analysis Results (LENGKAP)\n",
    "                self._create_comprehensive_detailed_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 2: Q-A Pairs Raw Data (HASIL PARSE LENGKAP) - FIXED SORTING\n",
    "                self._create_qa_pairs_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 3: Main Issue Analysis Details\n",
    "                self._create_main_issue_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 4: Reply Analysis Details\n",
    "                self._create_reply_analysis_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 5: Summary Statistics\n",
    "                self._create_summary_sheet(writer, stats)\n",
    "                \n",
    "                # Sheet 6: Performance Metrics\n",
    "                self._create_performance_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 7: Lead Time Analysis\n",
    "                self._create_lead_time_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 8: Quality Assessment\n",
    "                self._create_quality_sheet(writer, results)\n",
    "            \n",
    "            print(f\"‚úÖ COMPREHENSIVE results exported: {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting comprehensive results: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _create_qa_pairs_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan RAW Q-A PAIRS data - FIXED SORTING VERSION\"\"\"\n",
    "        qa_pairs_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_qa_pairs' in result:\n",
    "                # üî• FIX: URUTKAN Q-A PAIRS BERDASARKAN POSITION/WAKTU\n",
    "                sorted_qa_pairs = sorted(\n",
    "                    result['_raw_qa_pairs'], \n",
    "                    key=lambda x: x.get('position', 0)\n",
    "                )\n",
    "                \n",
    "                for i, qa_pair in enumerate(sorted_qa_pairs):\n",
    "                    qa_pairs_data.append({\n",
    "                        'Ticket_ID': result['ticket_id'],\n",
    "                        'QA_Pair_Index': i + 1,\n",
    "                        'Question': qa_pair.get('question', ''),\n",
    "                        'Question_Time': qa_pair.get('question_time'),\n",
    "                        'Bubble_Count': qa_pair.get('bubble_count', 1),\n",
    "                        'Is_Answered': qa_pair.get('is_answered', False),\n",
    "                        'Answer': qa_pair.get('answer', ''),\n",
    "                        'Answer_Time': qa_pair.get('answer_time'),\n",
    "                        'Answer_Role': qa_pair.get('answer_role', ''),\n",
    "                        'Lead_Time_Seconds': qa_pair.get('lead_time_seconds'),\n",
    "                        'Lead_Time_Minutes': qa_pair.get('lead_time_minutes'),\n",
    "                        'Lead_Time_HHMMSS': qa_pair.get('lead_time_hhmmss'),\n",
    "                        'Position_Index': qa_pair.get('position', i)  # Untuk debugging\n",
    "                    })\n",
    "        \n",
    "        if qa_pairs_data:\n",
    "            # üî• FIX: URUTKAN DATA UNTUK EXCEL BERDASARKAN TICKET DAN WAKTU\n",
    "            df_qa = pd.DataFrame(qa_pairs_data)\n",
    "            \n",
    "            # Urutkan berdasarkan Ticket_ID dan Question_Time\n",
    "            df_qa = df_qa.sort_values(['Ticket_ID', 'Question_Time']).reset_index(drop=True)\n",
    "            \n",
    "            # Update QA_Pair_Index yang benar setelah sorting\n",
    "            df_qa['QA_Pair_Index'] = df_qa.groupby('Ticket_ID').cumcount() + 1\n",
    "            \n",
    "            df_qa.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False)\n",
    "            \n",
    "            print(f\"   ‚úÖ Exported {len(df_qa)} Q-A pairs (sorted by time)\")\n",
    "        else:\n",
    "            # Create empty sheet jika tidak ada data\n",
    "            empty_df = pd.DataFrame(['No Q-A pairs data available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False, header=False)\n",
    "\n",
    "    def _create_comprehensive_detailed_sheet(self, writer, results):\n",
    "        \"\"\"Create DETAILED sheet dengan SEMUA data\"\"\"\n",
    "        detailed_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                row = {\n",
    "                    # BASIC INFO\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Status': 'SUCCESS',\n",
    "                    'Analysis_Timestamp': result['analysis_timestamp'],\n",
    "                    \n",
    "                    # CONVERSATION INFO\n",
    "                    'Total_Messages': result['total_messages'],\n",
    "                    'Total_QA_Pairs': result['total_qa_pairs'],\n",
    "                    'Answered_Pairs': result['answered_pairs'],\n",
    "                    'Conversation_Duration_Min': result.get('conversation_duration_minutes', 'N/A'),\n",
    "                    \n",
    "                    # MAIN ISSUE - LENGKAP\n",
    "                    'Main_Question': result['main_question'],\n",
    "                    'Main_Question_Time': result.get('main_question_time'),\n",
    "                    'Detected_Issue_Type': result.get('detected_issue_type', 'N/A'),\n",
    "                    'Final_Issue_Type': result['final_issue_type'],\n",
    "                    'Detection_Confidence': result['detection_confidence'],\n",
    "                    'ML_Prediction': result.get('ml_prediction', 'N/A'),\n",
    "                    'ML_Confidence': result.get('ml_confidence', 'N/A'),\n",
    "                    'Main_Issue_Reason': result.get('main_issue_reason', 'N/A'),\n",
    "                    \n",
    "                    # FIRST REPLY - LENGKAP\n",
    "                    'First_Reply_Found': result['first_reply_found'],\n",
    "                    'First_Reply_Message': result.get('first_reply_message', ''),\n",
    "                    'First_Reply_Time': result.get('first_reply_time'),\n",
    "                    'First_Reply_Lead_Time_Min': result.get('first_reply_lead_time_minutes'),\n",
    "                    'First_Reply_Lead_Time_HHMMSS': result.get('first_reply_lead_time_hhmmss'),\n",
    "                    \n",
    "                    # FINAL REPLY - LENGKAP\n",
    "                    'Final_Reply_Found': result['final_reply_found'],\n",
    "                    'Final_Reply_Message': result.get('final_reply_message', ''),\n",
    "                    'Final_Reply_Time': result.get('final_reply_time'),\n",
    "                    'Final_Reply_Lead_Time_Min': result.get('final_reply_lead_time_minutes'),\n",
    "                    'Final_Reply_Lead_Time_HHMMSS': result.get('final_reply_lead_time_hhmmss'),\n",
    "                    \n",
    "                    # PERFORMANCE METRICS\n",
    "                    'Performance_Rating': result['performance_rating'],\n",
    "                    'Response_Efficiency': result.get('response_efficiency', 'N/A'),\n",
    "                    'Resolution_Efficiency': result.get('resolution_efficiency', 'N/A'),\n",
    "                    'Quality_Rating': result['quality_rating'],\n",
    "                    'Quality_Score': result['quality_score'],\n",
    "                    \n",
    "                    # THRESHOLD & RECOMMENDATIONS\n",
    "                    'Threshold_Violations': ', '.join(result['threshold_violations']) if result['threshold_violations'] else 'None',\n",
    "                    'Recommendation': result['recommendation'],\n",
    "                    'Missing_Elements': ', '.join(result['missing_elements']) if result['missing_elements'] else 'None'\n",
    "                }\n",
    "            else:\n",
    "                row = {\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Status': 'FAILED',\n",
    "                    'Failure_Reason': result['failure_reason'],\n",
    "                    'Analysis_Timestamp': result['analysis_timestamp']\n",
    "                }\n",
    "            \n",
    "            detailed_data.append(row)\n",
    "        \n",
    "        df_detailed = pd.DataFrame(detailed_data)\n",
    "        df_detailed.to_excel(writer, sheet_name='Detailed_Analysis', index=False)\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        worksheet = writer.sheets['Detailed_Analysis']\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 50)\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    def _create_qa_pairs_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan RAW Q-A PAIRS data (HASIL PARSE LENGKAP)\"\"\"\n",
    "        qa_pairs_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_qa_pairs' in result:\n",
    "                for i, qa_pair in enumerate(result['_raw_qa_pairs']):\n",
    "                    qa_pairs_data.append({\n",
    "                        'Ticket_ID': result['ticket_id'],\n",
    "                        'QA_Pair_Index': i + 1,\n",
    "                        'Question': qa_pair.get('question', ''),\n",
    "                        'Question_Time': qa_pair.get('question_time'),\n",
    "                        'Bubble_Count': qa_pair.get('bubble_count', 1),\n",
    "                        'Is_Answered': qa_pair.get('is_answered', False),\n",
    "                        'Answer': qa_pair.get('answer', ''),\n",
    "                        'Answer_Time': qa_pair.get('answer_time'),\n",
    "                        'Answer_Role': qa_pair.get('answer_role', ''),\n",
    "                        'Lead_Time_Seconds': qa_pair.get('lead_time_seconds'),\n",
    "                        'Lead_Time_Minutes': qa_pair.get('lead_time_minutes'),\n",
    "                        'Lead_Time_HHMMSS': qa_pair.get('lead_time_hhmmss')\n",
    "                    })\n",
    "        \n",
    "        if qa_pairs_data:\n",
    "            df_qa = pd.DataFrame(qa_pairs_data)\n",
    "            df_qa.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False)\n",
    "        else:\n",
    "            # Create empty sheet jika tidak ada data\n",
    "            empty_df = pd.DataFrame(['No Q-A pairs data available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False, header=False)\n",
    "\n",
    "    def _create_main_issue_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan MAIN ISSUE analysis details\"\"\"\n",
    "        main_issue_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_main_issue' in result:\n",
    "                main_issue = result['_raw_main_issue']\n",
    "                scoring_details = main_issue.get('scoring_details', {})\n",
    "                \n",
    "                main_issue_data.append({\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Selected_Question': main_issue.get('question', ''),\n",
    "                    'Question_Time': main_issue.get('question_time'),\n",
    "                    'Issue_Type': main_issue.get('issue_type', ''),\n",
    "                    'Confidence_Score': main_issue.get('confidence_score', 0),\n",
    "                    'Selection_Reason': main_issue.get('selected_reason', ''),\n",
    "                    \n",
    "                    # SCORING DETAILS\n",
    "                    'Complaint_Keyword_Matches': scoring_details.get('complaint_matches', 0),\n",
    "                    'Serious_Keyword_Matches': scoring_details.get('serious_matches', 0),\n",
    "                    'Normal_Keyword_Matches': scoring_details.get('normal_matches', 0),\n",
    "                    'Is_Initial_Question': scoring_details.get('is_initial_question', False),\n",
    "                    'Is_Follow_Up': scoring_details.get('is_follow_up', False),\n",
    "                    \n",
    "                    # CANDIDATE COUNT\n",
    "                    'Total_Candidates': len(main_issue.get('all_candidates', [])),\n",
    "                    'Winning_Score': max([c.get('score', 0) for c in main_issue.get('all_candidates', [])]) if main_issue.get('all_candidates') else 0\n",
    "                })\n",
    "        \n",
    "        if main_issue_data:\n",
    "            df_main_issue = pd.DataFrame(main_issue_data)\n",
    "            df_main_issue.to_excel(writer, sheet_name='Main_Issue_Details', index=False)\n",
    "        else:\n",
    "            empty_df = pd.DataFrame(['No main issue details available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Main_Issue_Details', index=False, header=False)\n",
    "\n",
    "    def _create_reply_analysis_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan REPLY ANALYSIS details\"\"\"\n",
    "        reply_analysis_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_reply_analysis' in result:\n",
    "                reply_analysis = result['_raw_reply_analysis']\n",
    "                lead_times = reply_analysis.get('lead_times', {})\n",
    "                threshold_checks = reply_analysis.get('threshold_checks', {})\n",
    "                quality_assessment = reply_analysis.get('quality_assessment', {})\n",
    "                reply_validation = reply_analysis.get('reply_validation', {})\n",
    "                performance_analysis = reply_analysis.get('performance_analysis', {})\n",
    "                \n",
    "                reply_analysis_data.append({\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Issue_Type': reply_analysis.get('issue_type', ''),\n",
    "                    \n",
    "                    # LEAD TIMES DETAILS\n",
    "                    'First_Reply_Lead_Time_Seconds': lead_times.get('first_reply_lead_time_seconds'),\n",
    "                    'Final_Reply_Lead_Time_Seconds': lead_times.get('final_reply_lead_time_seconds'),\n",
    "                    'Conversation_Duration_Seconds': lead_times.get('conversation_duration_seconds'),\n",
    "                    \n",
    "                    # THRESHOLD CHECKS\n",
    "                    'Threshold_Violations_Count': len([v for v in threshold_checks.values() if v is True]),\n",
    "                    'Specific_Threshold_Violations': ', '.join([k for k, v in threshold_checks.items() if v is True]),\n",
    "                    \n",
    "                    # QUALITY ASSESSMENT\n",
    "                    'First_Reply_Quality': quality_assessment.get('first_reply_quality', 'unknown'),\n",
    "                    'Final_Reply_Quality': quality_assessment.get('final_reply_quality', 'unknown'),\n",
    "                    'Overall_Quality': quality_assessment.get('overall_quality', 'unknown'),\n",
    "                    \n",
    "                    # REPLY VALIDATION\n",
    "                    'First_Reply_Found': reply_validation.get('first_reply_found', False),\n",
    "                    'Final_Reply_Found': reply_validation.get('final_reply_found', False),\n",
    "                    'Validation_Quality_Score': reply_validation.get('quality_score', 0),\n",
    "                    'Validation_Quality_Rating': reply_validation.get('quality_rating', 'poor'),\n",
    "                    'Missing_Elements': ', '.join(reply_validation.get('missing_elements', [])),\n",
    "                    'Validation_Recommendation': reply_validation.get('recommendation', ''),\n",
    "                    \n",
    "                    # PERFORMANCE ANALYSIS\n",
    "                    'Performance_Rating': performance_analysis.get('performance_rating', 'unknown'),\n",
    "                    'Response_Efficiency': performance_analysis.get('response_efficiency', 'unknown'),\n",
    "                    'Resolution_Efficiency': performance_analysis.get('resolution_efficiency', 'unknown')\n",
    "                })\n",
    "        \n",
    "        if reply_analysis_data:\n",
    "            df_reply = pd.DataFrame(reply_analysis_data)\n",
    "            df_reply.to_excel(writer, sheet_name='Reply_Analysis_Details', index=False)\n",
    "        else:\n",
    "            empty_df = pd.DataFrame(['No reply analysis details available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Reply_Analysis_Details', index=False, header=False)\n",
    "\n",
    "    def _create_summary_sheet(self, writer, stats):\n",
    "        \"\"\"Create summary statistics sheet\"\"\"\n",
    "        summary_data = [\n",
    "            ['COMPREHENSIVE ANALYSIS SUMMARY - ALL DATA EXPORTED', ''],\n",
    "            ['Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "            ['Total Sheets in this File', '8 Sheets: Detailed, QA-Pairs, Main-Issue, Reply-Analysis, Summary, Performance, Lead-Time, Quality'],\n",
    "            ['', ''],\n",
    "            ['OVERALL STATISTICS', ''],\n",
    "            ['Total Tickets Processed', stats['total_tickets']],\n",
    "            ['Successful Analysis', stats['successful_analysis']],\n",
    "            ['Failed Analysis', stats['failed_analysis']],\n",
    "            ['Success Rate', f\"{stats['success_rate']*100:.1f}%\"],\n",
    "            ['Analysis Duration', f\"{stats['analysis_duration_seconds']:.1f} seconds\"],\n",
    "            ['Average Time per Ticket', f\"{stats['avg_analysis_time_per_ticket']:.2f} seconds\"],\n",
    "            ['', ''],\n",
    "            ['DATA COMPLETENESS', ''],\n",
    "            ['Total Q-A Pairs Extracted', 'See Raw_QA_Pairs sheet'],\n",
    "            ['Total Main Issues Identified', 'See Main_Issue_Details sheet'], \n",
    "            ['Total Reply Analyses', 'See Reply_Analysis_Details sheet'],\n",
    "            ['', ''],\n",
    "            ['EXPORT NOTES', ''],\n",
    "            ['Sheet 1 - Detailed_Analysis', 'Main results dengan semua field'],\n",
    "            ['Sheet 2 - Raw_QA_Pairs', 'SEMUA Q-A pairs yang berhasil di-parse'],\n",
    "            ['Sheet 3 - Main_Issue_Details', 'Detail scoring dan selection main issue'],\n",
    "            ['Sheet 4 - Reply_Analysis_Details', 'Detail analisis reply dan lead times'],\n",
    "            ['Sheet 5 - Summary_Statistics', 'Statistik aggregate'],\n",
    "            ['Sheet 6 - Performance_Metrics', 'Performance metrics per ticket'],\n",
    "            ['Sheet 7 - Lead_Time_Analysis', 'Analisis lead time detail'],\n",
    "            ['Sheet 8 - Quality_Assessment', 'Assesment kualitas conversation']\n",
    "        ]\n",
    "        \n",
    "        # Tambahkan statistik biasa\n",
    "        if 'issue_type_distribution' in stats:\n",
    "            summary_data.extend([['', ''], ['ISSUE TYPE DISTRIBUTION', '']])\n",
    "            for issue_type, count in stats['issue_type_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([f'{issue_type.title()} Issues', f'{count} ({percentage:.1f}%)'])\n",
    "        \n",
    "        if 'performance_distribution' in stats:\n",
    "            summary_data.extend([['', ''], ['PERFORMANCE DISTRIBUTION', '']])\n",
    "            for rating, count in stats['performance_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([f'{rating.upper()} Performance', f'{count} ({percentage:.1f}%)'])\n",
    "        \n",
    "        if 'lead_time_stats' in stats:\n",
    "            lt_stats = stats['lead_time_stats']\n",
    "            summary_data.extend([['', ''], ['LEAD TIME STATISTICS', '']])\n",
    "            summary_data.extend([\n",
    "                ['Average Lead Time', f\"{lt_stats['avg_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Median Lead Time', f\"{lt_stats['median_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Minimum Lead Time', f\"{lt_stats['min_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Maximum Lead Time', f\"{lt_stats['max_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Standard Deviation', f\"{lt_stats['std_lead_time_minutes']:.2f} minutes\"]\n",
    "            ])\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data, columns=['Metric', 'Value'])\n",
    "        summary_df.to_excel(writer, sheet_name='Summary_Statistics', index=False)\n",
    "\n",
    "    def _create_performance_sheet(self, writer, results):\n",
    "        \"\"\"Create performance metrics sheet\"\"\"\n",
    "        successful = [r for r in results if r['status'] == 'success']\n",
    "        \n",
    "        perf_data = []\n",
    "        for result in successful:\n",
    "            perf_data.append({\n",
    "                'Ticket_ID': result['ticket_id'],\n",
    "                'Issue_Type': result['final_issue_type'],\n",
    "                'Performance_Rating': result['performance_rating'],\n",
    "                'Response_Efficiency': result.get('response_efficiency', 'N/A'),\n",
    "                'Resolution_Efficiency': result.get('resolution_efficiency', 'N/A'),\n",
    "                'First_Reply_Lead_Time_Min': result.get('first_reply_lead_time_minutes'),\n",
    "                'Final_Reply_Lead_Time_Min': result.get('final_reply_lead_time_minutes'),\n",
    "                'Threshold_Violations_Count': len(result['threshold_violations']),\n",
    "                'Specific_Violations': ', '.join(result['threshold_violations']) if result['threshold_violations'] else 'None'\n",
    "            })\n",
    "        \n",
    "        df_perf = pd.DataFrame(perf_data)\n",
    "        df_perf.to_excel(writer, sheet_name='Performance_Metrics', index=False)\n",
    "\n",
    "    def _create_lead_time_sheet(self, writer, results):\n",
    "        \"\"\"Create lead time analysis sheet\"\"\"\n",
    "        successful = [r for r in results if r['status'] == 'success' and r.get('final_reply_lead_time_minutes')]\n",
    "        \n",
    "        lead_time_data = []\n",
    "        for result in successful:\n",
    "            lead_time_data.append({\n",
    "                'Ticket_ID': result['ticket_id'],\n",
    "                'Issue_Type': result['final_issue_type'],\n",
    "                'Final_Reply_Lead_Time_Min': result['final_reply_lead_time_minutes'],\n",
    "                'First_Reply_Lead_Time_Min': result.get('first_reply_lead_time_minutes', 'N/A'),\n",
    "                'Conversation_Duration_Min': result.get('conversation_duration_minutes', 'N/A'),\n",
    "                'Performance_Rating': result['performance_rating'],\n",
    "                'Within_Threshold': 'Yes' if not result['threshold_violations'] else 'No'\n",
    "            })\n",
    "        \n",
    "        df_lead = pd.DataFrame(lead_time_data)\n",
    "        df_lead.to_excel(writer, sheet_name='Lead_Time_Analysis', index=False)\n",
    "\n",
    "    def _create_quality_sheet(self, writer, results):\n",
    "        \"\"\"Create quality assessment sheet\"\"\"\n",
    "        successful = [r for r in results if r['status'] == 'success']\n",
    "        \n",
    "        quality_data = []\n",
    "        for result in successful:\n",
    "            quality_data.append({\n",
    "                'Ticket_ID': result['ticket_id'],\n",
    "                'Issue_Type': result['final_issue_type'],\n",
    "                'Quality_Rating': result['quality_rating'],\n",
    "                'Quality_Score': result['quality_score'],\n",
    "                'First_Reply_Found': 'Yes' if result['first_reply_found'] else 'No',\n",
    "                'Final_Reply_Found': 'Yes' if result['final_reply_found'] else 'No',\n",
    "                'Missing_Elements': ', '.join(result['missing_elements']) if result['missing_elements'] else 'None',\n",
    "                'Recommendation': result['recommendation']\n",
    "            })\n",
    "        \n",
    "        df_quality = pd.DataFrame(quality_data)\n",
    "        df_quality.to_excel(writer, sheet_name='Quality_Assessment', index=False)\n",
    "\n",
    "    def create_comprehensive_visualizations(self, results, stats):\n",
    "        \"\"\"Create comprehensive visualizations dashboard\"\"\"\n",
    "        print(\"üìä Creating comprehensive visualizations...\")\n",
    "        \n",
    "        # Import gridspec here to fix the NameError\n",
    "        import matplotlib.gridspec as gridspec\n",
    "        \n",
    "        successful = [r for r in results if r['status'] == 'success']\n",
    "        \n",
    "        if not successful:\n",
    "            print(\"‚ùå No successful analyses to visualize\")\n",
    "            return\n",
    "        \n",
    "        # Create figure dengan multiple subplots\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        fig.suptitle('Chat Analysis Dashboard - Comprehensive Overview', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Define grid layout\n",
    "        gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "        \n",
    "        # Plot 1: Issue Type Distribution\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        self._plot_issue_type_distribution(ax1, stats)\n",
    "        \n",
    "        # Plot 2: Performance Rating Distribution\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        self._plot_performance_distribution(ax2, stats)\n",
    "        \n",
    "        # Plot 3: Lead Time Distribution\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        self._plot_lead_time_distribution(ax3, successful)\n",
    "        \n",
    "        # Plot 4: Quality Score Distribution\n",
    "        ax4 = fig.add_subplot(gs[1, 0])\n",
    "        self._plot_quality_distribution(ax4, successful)\n",
    "        \n",
    "        # Plot 5: Reply Effectiveness\n",
    "        ax5 = fig.add_subplot(gs[1, 1])\n",
    "        self._plot_reply_effectiveness(ax5, stats)\n",
    "        \n",
    "        # Plot 6: Threshold Violations\n",
    "        ax6 = fig.add_subplot(gs[1, 2])\n",
    "        self._plot_threshold_violations(ax6, stats)\n",
    "        \n",
    "        # Plot 7: Lead Time by Issue Type\n",
    "        ax7 = fig.add_subplot(gs[2, :])\n",
    "        self._plot_lead_time_by_issue_type(ax7, successful)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.93)\n",
    "        \n",
    "        # Save dashboard\n",
    "        dashboard_path = f\"{self.visualizations_dir}analysis_dashboard.png\"\n",
    "        plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"‚úÖ Visualizations saved: {dashboard_path}\")\n",
    "        \n",
    "        # Create additional individual charts\n",
    "        self._create_individual_charts(successful, stats)\n",
    "    \n",
    "    def _plot_issue_type_distribution(self, ax, stats):\n",
    "        \"\"\"Plot issue type distribution\"\"\"\n",
    "        if 'issue_type_distribution' not in stats:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        types = list(stats['issue_type_distribution'].keys())\n",
    "        counts = list(stats['issue_type_distribution'].values())\n",
    "        colors = [self.colors.get(t, '#999999') for t in types]\n",
    "        \n",
    "        ax.pie(counts, labels=types, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax.set_title('Issue Type Distribution', fontweight='bold')\n",
    "    \n",
    "    def _plot_performance_distribution(self, ax, stats):\n",
    "        \"\"\"Plot performance rating distribution\"\"\"\n",
    "        if 'performance_distribution' not in stats:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        ratings = list(stats['performance_distribution'].keys())\n",
    "        counts = list(stats['performance_distribution'].values())\n",
    "        colors = [self.performance_colors.get(r, '#999999') for r in ratings]\n",
    "        \n",
    "        bars = ax.bar(ratings, counts, color=colors)\n",
    "        ax.set_title('Performance Rating Distribution', fontweight='bold')\n",
    "        ax.set_ylabel('Number of Tickets')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    def _plot_lead_time_distribution(self, ax, successful):\n",
    "        \"\"\"Plot lead time distribution\"\"\"\n",
    "        lead_times = [r.get('final_reply_lead_time_minutes', 0) for r in successful \n",
    "                     if r.get('final_reply_lead_time_minutes') is not None]\n",
    "        \n",
    "        if not lead_times:\n",
    "            ax.text(0.5, 0.5, 'No lead time data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        ax.hist(lead_times, bins=15, alpha=0.7, color='#2E86AB', edgecolor='black')\n",
    "        ax.set_title('Final Reply Lead Time Distribution', fontweight='bold')\n",
    "        ax.set_xlabel('Lead Time (minutes)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        # Add statistics\n",
    "        avg_lt = np.mean(lead_times)\n",
    "        ax.axvline(avg_lt, color='red', linestyle='--', label=f'Average: {avg_lt:.1f} min')\n",
    "        ax.legend()\n",
    "    \n",
    "    def _plot_quality_distribution(self, ax, successful):\n",
    "        \"\"\"Plot quality score distribution\"\"\"\n",
    "        quality_scores = [r.get('quality_score', 0) for r in successful]\n",
    "        \n",
    "        ax.hist(quality_scores, bins=range(0, 8), alpha=0.7, color='#F18F01', edgecolor='black')\n",
    "        ax.set_title('Quality Score Distribution', fontweight='bold')\n",
    "        ax.set_xlabel('Quality Score (0-6)')\n",
    "        ax.set_ylabel('Number of Tickets')\n",
    "        ax.set_xticks(range(0, 7))\n",
    "    \n",
    "    def _plot_reply_effectiveness(self, ax, stats):\n",
    "        \"\"\"Plot reply effectiveness metrics\"\"\"\n",
    "        if 'reply_effectiveness' not in stats:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        eff = stats['reply_effectiveness']\n",
    "        metrics = ['First Reply\\nFound', 'Final Reply\\nFound', 'Both Replies\\nFound']\n",
    "        rates = [eff['first_reply_found_rate'] * 100, \n",
    "                eff['final_reply_found_rate'] * 100,\n",
    "                eff['both_replies_found_rate'] * 100]\n",
    "        \n",
    "        bars = ax.bar(metrics, rates, color=['#2E86AB', '#A23B72', '#F18F01'])\n",
    "        ax.set_title('Reply Effectiveness Rates', fontweight='bold')\n",
    "        ax.set_ylabel('Rate (%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for bar, rate in zip(bars, rates):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                   f'{rate:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    def _plot_threshold_violations(self, ax, stats):\n",
    "        \"\"\"Plot threshold violations\"\"\"\n",
    "        if 'threshold_violations' not in stats or not stats['threshold_violations']:\n",
    "            ax.text(0.5, 0.5, 'No threshold violations', ha='center', va='center', fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        violations = list(stats['threshold_violations'].keys())\n",
    "        counts = list(stats['threshold_violations'].values())\n",
    "        \n",
    "        bars = ax.bar(violations, counts, color='#C73E1D')\n",
    "        ax.set_title('Threshold Violations', fontweight='bold')\n",
    "        ax.set_ylabel('Number of Occurrences')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    def _plot_lead_time_by_issue_type(self, ax, successful):\n",
    "        \"\"\"Plot lead time by issue type\"\"\"\n",
    "        issue_data = {}\n",
    "        for result in successful:\n",
    "            issue_type = result['final_issue_type']\n",
    "            lead_time = result.get('final_reply_lead_time_minutes')\n",
    "            if lead_time is not None:\n",
    "                if issue_type not in issue_data:\n",
    "                    issue_data[issue_type] = []\n",
    "                issue_data[issue_type].append(lead_time)\n",
    "        \n",
    "        if not issue_data:\n",
    "            ax.text(0.5, 0.5, 'No lead time data by issue type', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        # Prepare data for box plot\n",
    "        labels = list(issue_data.keys())\n",
    "        data = [issue_data[label] for label in labels]\n",
    "        colors = [self.colors.get(label, '#999999') for label in labels]\n",
    "        \n",
    "        box_plot = ax.boxplot(data, labels=labels, patch_artist=True)\n",
    "        \n",
    "        # Color the boxes\n",
    "        for patch, color in zip(box_plot['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax.set_title('Lead Time Distribution by Issue Type', fontweight='bold')\n",
    "        ax.set_ylabel('Lead Time (minutes)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _create_individual_charts(self, successful, stats):\n",
    "        \"\"\"Create additional individual charts\"\"\"\n",
    "        # 1. Performance by Issue Type\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        performance_by_type = {}\n",
    "        for result in successful:\n",
    "            issue_type = result['final_issue_type']\n",
    "            performance = result['performance_rating']\n",
    "            if issue_type not in performance_by_type:\n",
    "                performance_by_type[issue_type] = []\n",
    "            performance_by_type[issue_type].append(performance)\n",
    "        \n",
    "        # Convert to counts\n",
    "        plot_data = {}\n",
    "        for issue_type, performances in performance_by_type.items():\n",
    "            plot_data[issue_type] = Counter(performances)\n",
    "        \n",
    "        # Create stacked bar chart\n",
    "        ratings = ['excellent', 'good', 'fair', 'poor']\n",
    "        bottom = np.zeros(len(plot_data))\n",
    "        \n",
    "        for i, rating in enumerate(ratings):\n",
    "            counts = [plot_data[issue_type].get(rating, 0) for issue_type in plot_data.keys()]\n",
    "            ax.bar(plot_data.keys(), counts, bottom=bottom, label=rating.capitalize(), \n",
    "                  color=self.performance_colors.get(rating, '#999999'))\n",
    "            bottom += counts\n",
    "        \n",
    "        ax.set_title('Performance Rating by Issue Type', fontweight='bold')\n",
    "        ax.set_ylabel('Number of Tickets')\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.visualizations_dir}performance_by_issue_type.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"‚úÖ Individual charts created in {self.visualizations_dir}\")\n",
    "\n",
    "# Initialize Enhanced Results Exporter\n",
    "exporter = ResultsExporter()\n",
    "\n",
    "print(\"‚úÖ ENHANCED Results Exporter & Visualizer Ready!\")\n",
    "print(\"   ‚úì 8 Sheets Excel Export\")\n",
    "print(\"   ‚úì Complete Q-A Pairs Data\") \n",
    "print(\"   ‚úì Main Issue Scoring Details\")\n",
    "print(\"   ‚úì Reply Analysis Details\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
